<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.5.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="PENG, Cong">

  
  
  
    
  
  <meta name="description" content="Thanks to [pmarcelino](https://www.kaggle.com/pmarcelino /comprehensive-data-exploration-with-python) and serigne for their great work.
This is my second kaggle competition to practice on the knowledge of data analysis and machine learning. Unlike the Titanic competition, this house prices is a regression problem. So there will be much difference from the previous binary classification. For this competition, we will have 79 variables that describe various aspects of a house and with a price in the training data set.">

  
  <link rel="alternate" hreflang="en-us" href="https://pcx.linkedinfo.co/post/houseprice/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.3f344b41a854a4e86bdc347bbce3b34a.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-87823019-3', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="https://www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://pcx.linkedinfo.co/post/houseprice/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Cong Peng">
  <meta property="og:url" content="https://pcx.linkedinfo.co/post/houseprice/">
  <meta property="og:title" content="Explore the house prices kaggle competition | Cong Peng">
  <meta property="og:description" content="Thanks to [pmarcelino](https://www.kaggle.com/pmarcelino /comprehensive-data-exploration-with-python) and serigne for their great work.
This is my second kaggle competition to practice on the knowledge of data analysis and machine learning. Unlike the Titanic competition, this house prices is a regression problem. So there will be much difference from the previous binary classification. For this competition, we will have 79 variables that describe various aspects of a house and with a price in the training data set."><meta property="og:image" content="https://pcx.linkedinfo.co/img/icon-192.png">
  <meta property="twitter:image" content="https://pcx.linkedinfo.co/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-06-11T17:38:33&#43;02:00">
    
    <meta property="article:modified_time" content="2019-09-13T22:06:13&#43;02:00">
  

  


    






  





  





  





<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://pcx.linkedinfo.co/post/houseprice/"
  },
  "headline": "Explore the house prices kaggle competition",
  
  "datePublished": "2019-06-11T17:38:33+02:00",
  "dateModified": "2019-09-13T22:06:13+02:00",
  
  "author": {
    "@type": "Person",
    "name": "PENG, Cong"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Cong Peng",
    "logo": {
      "@type": "ImageObject",
      "url": "https://pcx.linkedinfo.co/img/icon-512.png"
    }
  },
  "description": "Thanks to [pmarcelino](https://www.kaggle.com/pmarcelino /comprehensive-data-exploration-with-python) and serigne for their great work.\nThis is my second kaggle competition to practice on the knowledge of data analysis and machine learning. Unlike the Titanic competition, this house prices is a regression problem. So there will be much difference from the previous binary classification. For this competition, we will have 79 variables that describe various aspects of a house and with a price in the training data set."
}
</script>

  

  


  


  





  <title>Explore the house prices kaggle competition | Cong Peng</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Cong Peng</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Explore the house prices kaggle competition</h1>

  

  
    



<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Sep 13, 2019
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    11 min read
  </span>
  

  
  
  

  
  

  
    

  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>Thanks to [pmarcelino](<a href="https://www.kaggle.com/pmarcelino">https://www.kaggle.com/pmarcelino</a>
/comprehensive-data-exploration-with-python) and
<a href="https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard">serigne</a> for their great work.</p>
<p>This is my second kaggle competition to practice on the knowledge of data
analysis and machine learning. Unlike the Titanic competition, this house
prices is a regression problem. So there will be much difference from the
previous binary classification. For this competition, we will have 79
variables that describe various aspects of a house and with a price in the
training data set. And then predict the prices of houses in the testing set
based on the 79 variables. This will be a long journey with the 79 variables.
So let&rsquo;s start to explore the data with the data description.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> os
<span style="color:#75715e"># from typing import List, Union</span>
<span style="color:#75715e"># from pysnooper import snoop</span>

<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#75715e"># import matplotlib.pyplot as plt</span>
<span style="color:#75715e"># import numpy as np</span>

loc <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;house price&#39;</span>
<span style="color:#66d9ef">if</span> os<span style="color:#f92672">.</span>getcwd()<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;/&#39;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">!=</span> loc:
    os<span style="color:#f92672">.</span>chdir(loc)

df_train <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(f<span style="color:#e6db74">&#39;input/train.csv&#39;</span>)
df_test <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(f<span style="color:#e6db74">&#39;input/test.csv&#39;</span>)
</code></pre></div><h1 id="data-exploration">Data exploration</h1>
<p>Let&rsquo;s firstly have a look at the data we have.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(df_train<span style="color:#f92672">.</span>shape)
df_train<span style="color:#f92672">.</span>head()
</code></pre></div><pre><code>(1460, 81)
</code></pre>
<!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(df_test<span style="color:#f92672">.</span>shape)
df_test<span style="color:#f92672">.</span>head()
</code></pre></div><pre><code>(1459, 80)
</code></pre>
<!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<p>So we have 1460 rows in training set and 1459 rows in testing
set. Besides the price col in the training set, both data sets have 79 cols of
variables + 1 col of &lsquo;Id&rsquo;.</p>
<h2 id="check-missing-values">Check missing values</h2>
<p>Now let&rsquo;s check if there is any missing value in the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cols_missing_value</span>(df):
    df_null_sum <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>isnull()<span style="color:#f92672">.</span>sum()
    df_na <span style="color:#f92672">=</span> (df<span style="color:#f92672">.</span>isnull()<span style="color:#f92672">.</span>sum() <span style="color:#f92672">/</span> len(df)) <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>
    missing_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat({<span style="color:#e6db74">&#39;Missing Ratio %&#39;</span>: df_na,
                              <span style="color:#e6db74">&#39;Total&#39;</span>: df_null_sum}, axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)
    <span style="color:#66d9ef">return</span> missing_data<span style="color:#f92672">.</span>drop(missing_data[missing_data[<span style="color:#e6db74">&#39;Total&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>index
                             )<span style="color:#f92672">.</span>sort_values(by<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Total&#39;</span>, ascending<span style="color:#f92672">=</span>False)


cols_missing_value(df_train)
</code></pre></div><!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cols_missing_value(pd<span style="color:#f92672">.</span>concat((df_train[df_test<span style="color:#f92672">.</span>columns], df_test)))
</code></pre></div><!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<p>There are quite a lot of missing values, some cols are missing almost all of the data. We need to handle the missing values by imputation or other methods later.</p>
<h2 id="a-look-at-distributions">A look at distributions</h2>
<p>As we&rsquo;re predicting the &lsquo;SalePrice&rsquo;, so we should have a look at the stats of
this col.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_train[<span style="color:#e6db74">&#39;SalePrice&#39;</span>]<span style="color:#f92672">.</span>describe()
</code></pre></div><pre><code>count      1460.000000
mean     180921.195890
std       79442.502883
min       34900.000000
25%      129975.000000
50%      163000.000000
75%      214000.000000
max      755000.000000
Name: SalePrice, dtype: float64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_train[<span style="color:#e6db74">&#39;SalePrice&#39;</span>]<span style="color:#f92672">.</span>hist(bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>)
</code></pre></div><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11414e4a8&gt;
</code></pre>
<p><img src="output_12_1.svg" alt="svg"></p>
<p>The values of &lsquo;SalePrice&rsquo; does fall in a normal distribution. In general, learning algorithms benefit from standardization of the data set. So we&rsquo;ll transform the target values by <code>QuantileTransformer</code> and <code>TransformedTargetRegressor</code> later when training and testing.</p>
<p>Now let&rsquo;s have a look at other columns&rsquo; skewnesses.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> skew

<span style="color:#75715e"># Concat training and testing sets together to see the full picture</span>
df_all <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat((df_train, df_test))<span style="color:#f92672">.</span>reset_index(
    drop<span style="color:#f92672">=</span>True)<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;SalePrice&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)

numeric_cols <span style="color:#f92672">=</span> df_all<span style="color:#f92672">.</span>select_dtypes(
    exclude<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;object&#39;</span>, <span style="color:#e6db74">&#39;category&#39;</span>])<span style="color:#f92672">.</span>columns

<span style="color:#75715e"># Check the skewness of the numerical cols</span>
skewed_cols <span style="color:#f92672">=</span> df_all[numeric_cols]<span style="color:#f92672">.</span>apply(
    <span style="color:#66d9ef">lambda</span> col: skew(col))<span style="color:#f92672">.</span>sort_values(ascending<span style="color:#f92672">=</span>False)

skewness <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;Skewness&#39;</span>: skewed_cols})
skewness<span style="color:#f92672">.</span>head(<span style="color:#ae81ff">10</span>)

skewness <span style="color:#f92672">=</span> skewness[abs(skewness[<span style="color:#e6db74">&#39;Skewness&#39;</span>]) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.75</span>]
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{skewness.shape[0]} skewed numerical columns.&#39;</span>)

df_all[skewness<span style="color:#f92672">.</span>index]<span style="color:#f92672">.</span>hist(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">14</span>, <span style="color:#ae81ff">12</span>))
</code></pre></div><pre><code>/Users/pcx/.pyenv/versions/ml/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  &quot;&quot;&quot;
15 skewed numerical columns.


array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1209d3550&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1041d86d8&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x104200c50&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x104233208&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x120b97780&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120bc1cf8&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120bef2b0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120c17860&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x120c17898&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120c71358&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120f2a8d0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120f53e48&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x120f84400&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120fac978&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x120fd3ef0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1210054a8&gt;]],
      dtype=object)
</code></pre>
<p><img src="output_14_2.svg" alt="svg"></p>
<p>We also need to handle the skewed variables later.</p>
<h1 id="preprocessing-data">Preprocessing data</h1>
<h2 id="impute-missing-values">Impute missing values</h2>
<p>There are quite a lot of missing values, some cols are missing almost all of
the data. Now look into the data description to see what the variables really
are and how should we deal with them.
We&rsquo;re now concating the training set and testing set since we need to handle
the missing values in both data sets. We will split them when we need.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># keep Id col for later unpack training and testing df</span>
ids_train <span style="color:#f92672">=</span> df_train[<span style="color:#e6db74">&#39;Id&#39;</span>]
ids_test <span style="color:#f92672">=</span> df_test[<span style="color:#e6db74">&#39;Id&#39;</span>]
Y_train <span style="color:#f92672">=</span> df_train[<span style="color:#e6db74">&#39;SalePrice&#39;</span>]<span style="color:#f92672">.</span>values
df_all <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat((df_train, df_test))<span style="color:#f92672">.</span>reset_index(
    drop<span style="color:#f92672">=</span>True)<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;SalePrice&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)
</code></pre></div><pre><code>/Users/pcx/.pyenv/versions/ml/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.
</code></pre>
<p>&lsquo;PoolQC&rsquo; (Pool quality) is the one with most missing values, and NA stands for &ldquo;No Pool&rdquo; (described in data_description.txt), so the missing values should be replaced by str &ldquo;No Pool&rdquo;. And this col should be an ordered categorical variable.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all[<span style="color:#e6db74">&#39;PoolQC&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;PoolQC&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Pool&#34;</span>)
</code></pre></div><p>The same applies to &lsquo;MiscFeature&rsquo;, &lsquo;Alley&rsquo;, &lsquo;Fence&rsquo;, &lsquo;FireplaceQu&rsquo;,
&lsquo;GarageType&rsquo;, &lsquo;GarageFinish&rsquo;, &lsquo;GarageQual&rsquo;, &lsquo;GarageCond&rsquo;, &lsquo;BsmtQual&rsquo;,
&lsquo;BsmtCond&rsquo;, &lsquo;BsmtExposure&rsquo;, &lsquo;BsmtFinType1&rsquo;, &lsquo;BsmtFinType2&rsquo;, &lsquo;MasVnrType&rsquo;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all[<span style="color:#e6db74">&#39;MiscFeature&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;MiscFeature&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;None&#34;</span>)
df_all[<span style="color:#e6db74">&#39;Alley&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;Alley&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Alley access&#34;</span>)
df_all[<span style="color:#e6db74">&#39;Fence&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;Fence&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Fence&#34;</span>)
df_all[<span style="color:#e6db74">&#39;FireplaceQu&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;FireplaceQu&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Fireplace&#34;</span>)
df_all[<span style="color:#e6db74">&#39;GarageType&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageType&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Garage&#34;</span>)
df_all[<span style="color:#e6db74">&#39;GarageFinish&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageFinish&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Garage&#34;</span>)
df_all[<span style="color:#e6db74">&#39;GarageQual&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageQual&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Garage&#34;</span>)
df_all[<span style="color:#e6db74">&#39;GarageCond&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageCond&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Garage&#34;</span>)
df_all[<span style="color:#e6db74">&#39;BsmtCond&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;BsmtCond&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Basement&#34;</span>)
df_all[<span style="color:#e6db74">&#39;BsmtQual&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;BsmtQual&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Basement&#34;</span>)
df_all[<span style="color:#e6db74">&#39;BsmtExposure&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;BsmtExposure&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Basement&#34;</span>)
df_all[<span style="color:#e6db74">&#39;BsmtFinType1&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;BsmtFinType1&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Basement&#34;</span>)
df_all[<span style="color:#e6db74">&#39;BsmtFinType2&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;BsmtFinType2&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;No Basement&#34;</span>)
</code></pre></div><p>Now let&rsquo;s check &lsquo;GarageYrBlt&rsquo;, &lsquo;GarageArea&rsquo;, &lsquo;GarageCars&rsquo;.
Since only 1 record of &lsquo;GarageCars&rsquo; is missing, and it&rsquo;s &lsquo;GarageType&rsquo; is
&lsquo;Detchd&rsquo;, so let&rsquo;s make it as size of the mode/median of &lsquo;GarageCars&rsquo; when
type is &lsquo;Detchd&rsquo;.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all[df_all[<span style="color:#e6db74">&#39;GarageCars&#39;</span>]<span style="color:#f92672">.</span>isnull()]
df_all[df_all[<span style="color:#e6db74">&#39;GarageCars&#39;</span>]<span style="color:#f92672">.</span>isnull()][<span style="color:#e6db74">&#39;GarageType&#39;</span>]
df_all[<span style="color:#e6db74">&#39;GarageCars&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageCars&#39;</span>]<span style="color:#f92672">.</span>fillna(
    int(df_all[df_all[<span style="color:#e6db74">&#39;GarageType&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Detchd&#39;</span>][<span style="color:#e6db74">&#39;GarageCars&#39;</span>]<span style="color:#f92672">.</span>mode()))
</code></pre></div><p>It&rsquo;s the same record for the missing &lsquo;GarageArea&rsquo; value, as we filled its
&lsquo;GarageCars&rsquo; to the mode value, we will fill the area as the mean value of
&lsquo;GarageArea&rsquo; where the &lsquo;GarageCars&rsquo; == mode value of &lsquo;Detchd&rsquo;.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all[df_all[<span style="color:#e6db74">&#39;GarageArea&#39;</span>]<span style="color:#f92672">.</span>isnull()]
df_all[<span style="color:#e6db74">&#39;GarageArea&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageArea&#39;</span>]<span style="color:#f92672">.</span>fillna(
    df_all[df_all[<span style="color:#e6db74">&#39;GarageType&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Detchd&#39;</span>][<span style="color:#e6db74">&#39;GarageArea&#39;</span>]<span style="color:#f92672">.</span>mean())

<span style="color:#75715e"># df_all[df_all[&#39;GarageYrBlt&#39;].isnull()][&#39;GarageType&#39;]</span>
</code></pre></div><p>For the records that have no garage, we set the null value of &lsquo;GarageYrBlt&rsquo;
to 0, but for the records with type &lsquo;Detchd&rsquo;, we set the null value to the median
value of the built year with type &lsquo;Detchd&rsquo;.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">year_median <span style="color:#f92672">=</span> df_all[df_all[<span style="color:#e6db74">&#39;GarageType&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Detchd&#39;</span>][<span style="color:#e6db74">&#39;GarageYrBlt&#39;</span>]<span style="color:#f92672">.</span>median()
df_all[<span style="color:#e6db74">&#39;GarageYrBlt&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageYrBlt&#39;</span>][
    df_all[<span style="color:#e6db74">&#39;GarageType&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Detchd&#39;</span>]<span style="color:#f92672">.</span>fillna(year_median)

df_all[<span style="color:#e6db74">&#39;GarageYrBlt&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;GarageYrBlt&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
</code></pre></div><p>Since there are quite many missing value for &lsquo;LotFrontage&rsquo; (16.65%), we would drop this col.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all <span style="color:#f92672">=</span> df_all<span style="color:#f92672">.</span>drop(<span style="color:#e6db74">&#39;LotFrontage&#39;</span>, axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)
</code></pre></div><p>Filling with 0 for those likely to be 0.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">bsmt_zero_missing <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;BsmtFinSF1&#39;</span>, <span style="color:#e6db74">&#39;BsmtFinSF2&#39;</span>,
                     <span style="color:#e6db74">&#39;BsmtUnfSF&#39;</span>, <span style="color:#e6db74">&#39;TotalBsmtSF&#39;</span>, <span style="color:#e6db74">&#39;BsmtFullBath&#39;</span>, <span style="color:#e6db74">&#39;BsmtHalfBath&#39;</span>]

<span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> bsmt_zero_missing:
    df_all[col] <span style="color:#f92672">=</span> df_all[col]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
</code></pre></div><p>&lsquo;MasVnrArea&rsquo; and &lsquo;MasVnrType&rsquo;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all[df_all[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>]<span style="color:#f92672">.</span>isnull()][<span style="color:#e6db74">&#39;MasVnrArea&#39;</span>]
df_all[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>]<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;category&#39;</span>)<span style="color:#f92672">.</span>value_counts()
</code></pre></div><pre><code>None       1742
BrkFace     879
Stone       249
BrkCmn       25
Name: MasVnrType, dtype: int64
</code></pre>
<p>For all the records with missing values of &lsquo;MasVnrType&rsquo;, 1 record with
&lsquo;MasVnrArea&rsquo; is not NaN, so we filling its type as &lsquo;BrkFace&rsquo;, which is the
most occurred none-None type. Other missing values of &lsquo;MasVnrType&rsquo; we will
fill in with the most common <code>None</code>, so its &lsquo;MasVnrArea&rsquo; will be 0.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>][
    df_all[<span style="color:#e6db74">&#39;MasVnrArea&#39;</span>]<span style="color:#f92672">.</span>notna()]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;BrkFace&#39;</span>)
df_all[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
df_all[<span style="color:#e6db74">&#39;MasVnrArea&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;MasVnrArea&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
</code></pre></div><p>Set the NaN to the mostly occurred value &lsquo;RL&rsquo;.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_all[<span style="color:#e6db74">&#39;MSZoning&#39;</span>]<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;category&#39;</span>)<span style="color:#f92672">.</span>value_counts()
df_all[<span style="color:#e6db74">&#39;MSZoning&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;MSZoning&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;RL&#39;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Set the NaN to the mostly occurred value &#39;AllPub&#39;.</span>
df_all[<span style="color:#e6db74">&#39;Utilities&#39;</span>]<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;category&#39;</span>)<span style="color:#f92672">.</span>value_counts()
df_all[<span style="color:#e6db74">&#39;Utilities&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;Utilities&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;AllPub&#39;</span>)

<span style="color:#75715e"># keep or not?</span>
df_all <span style="color:#f92672">=</span> df_all<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;Utilities&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)
</code></pre></div><p>Set NaN to mostly occurred value for the rest cols.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cols_nan_mode <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Functional&#39;</span>, <span style="color:#e6db74">&#39;Electrical&#39;</span>, <span style="color:#e6db74">&#39;KitchenQual&#39;</span>,
                 <span style="color:#e6db74">&#39;Exterior1st&#39;</span>, <span style="color:#e6db74">&#39;Exterior2nd&#39;</span>, <span style="color:#e6db74">&#39;SaleType&#39;</span>, <span style="color:#e6db74">&#39;MSSubClass&#39;</span>]

<span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> cols_nan_mode:
    df_all[col] <span style="color:#f92672">=</span> df_all[col]<span style="color:#f92672">.</span>fillna(df_all[col]<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>])

cols_missing_value(df_all)
</code></pre></div><!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<p>Now there&rsquo;s no missing values. Let&rsquo;s move to the next part.</p>
<h2 id="transform-categorical-variables">Transform categorical variables</h2>
<p>We&rsquo;ll firstly transform some of the variables from numerical to categorical as
they should be. And add one variable.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cols_num_cat <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;MSSubClass&#39;</span>, <span style="color:#e6db74">&#39;YrSold&#39;</span>, <span style="color:#e6db74">&#39;MoSold&#39;</span>]
<span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> cols_num_cat:
    df_all[col] <span style="color:#f92672">=</span> df_all[col]<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;category&#39;</span>)

<span style="color:#75715e"># Adding total sqfootage feature</span>
df_all[<span style="color:#e6db74">&#39;TotalSF&#39;</span>] <span style="color:#f92672">=</span> df_all[<span style="color:#e6db74">&#39;TotalBsmtSF&#39;</span>] <span style="color:#f92672">+</span> \
    df_all[<span style="color:#e6db74">&#39;1stFlrSF&#39;</span>] <span style="color:#f92672">+</span> df_all[<span style="color:#e6db74">&#39;2ndFlrSF&#39;</span>]
</code></pre></div><h2 id="check-and-handle-outliers">Check and handle outliers</h2>
<p>After handling the missing values, now we have a look at if there are outliers
in the training set with the target variable by scatter plots.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

df_train <span style="color:#f92672">=</span> df_all[:len(ids_train)]
df_test <span style="color:#f92672">=</span> df_all[len(ids_train):]

cols <span style="color:#f92672">=</span> df_train<span style="color:#f92672">.</span>select_dtypes([<span style="color:#e6db74">&#39;int64&#39;</span>, <span style="color:#e6db74">&#39;float64&#39;</span>])
<span style="color:#75715e"># cols = df_train.select_dtypes([&#39;int64&#39;, &#39;float64&#39;])</span>
df_train <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([df_train, pd<span style="color:#f92672">.</span>DataFrame(
    Y_train, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;SalePrice&#39;</span>])], axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)

fig, axes <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">6</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">30</span>))
<span style="color:#66d9ef">for</span> i, col <span style="color:#f92672">in</span> enumerate(cols):
    df_train<span style="color:#f92672">.</span>plot<span style="color:#f92672">.</span>scatter(x<span style="color:#f92672">=</span>col, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;SalePrice&#39;</span>, ax<span style="color:#f92672">=</span>axes[i <span style="color:#f92672">//</span> <span style="color:#ae81ff">6</span>, i <span style="color:#f92672">%</span> <span style="color:#ae81ff">6</span>])
</code></pre></div><p><img src="output_44_0.svg" alt="svg"></p>
<p>The continuous variable &lsquo;GrLivArea&rsquo; seems having 2 values have very
different &ldquo;hehavior&rdquo;. The 2 bottom right dots may be very inferential that
have quite big areas but low prices. Let&rsquo;s remove them to see if it&rsquo;s better
for the results. After removing these 2 rows, we would see that outliers in
other cols such &lsquo;TotalBsmtSF&rsquo; and &lsquo;TotalSF&rsquo; are disappeared as well.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df_train <span style="color:#f92672">=</span> df_train<span style="color:#f92672">.</span>drop(df_train[(df_train[<span style="color:#e6db74">&#39;GrLivArea&#39;</span>] <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">4000</span>) <span style="color:#f92672">&amp;</span>
                                  (df_train[<span style="color:#e6db74">&#39;SalePrice&#39;</span>] <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">250000</span>)]<span style="color:#f92672">.</span>index)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Packing back data sets after removing outliers in training set.</span>
ids_train <span style="color:#f92672">=</span> df_train[<span style="color:#e6db74">&#39;Id&#39;</span>]
ids_test <span style="color:#f92672">=</span> df_test[<span style="color:#e6db74">&#39;Id&#39;</span>]
Y_train <span style="color:#f92672">=</span> df_train[<span style="color:#e6db74">&#39;SalePrice&#39;</span>]<span style="color:#f92672">.</span>values
df_all <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat((df_train, df_test))<span style="color:#f92672">.</span>reset_index(
    drop<span style="color:#f92672">=</span>True)<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;SalePrice&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)
</code></pre></div><h2 id="transform-skewed-variables">Transform skewed variables</h2>
<p>We will transform the skewed variables into normal distributions by
<code>quantile_transform</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">numeric_cols <span style="color:#f92672">=</span> df_all<span style="color:#f92672">.</span>select_dtypes(
    exclude<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;object&#39;</span>, <span style="color:#e6db74">&#39;category&#39;</span>])<span style="color:#f92672">.</span>columns

<span style="color:#75715e"># Check the skewnesses of the numerical cols</span>
skewed_cols <span style="color:#f92672">=</span> df_all[numeric_cols]<span style="color:#f92672">.</span>apply(
    <span style="color:#66d9ef">lambda</span> col: skew(col))<span style="color:#f92672">.</span>sort_values(ascending<span style="color:#f92672">=</span>False)

skewness <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;Skewness&#39;</span>: skewed_cols})

skewness <span style="color:#f92672">=</span> skewness[abs(skewness[<span style="color:#e6db74">&#39;Skewness&#39;</span>]) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.75</span>]
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{skewness.shape[0]} skewed numerical columns.&#39;</span>)

<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> quantile_transform
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

skewed_features <span style="color:#f92672">=</span> skewness<span style="color:#f92672">.</span>index
df_all[skewed_features] <span style="color:#f92672">=</span> quantile_transform(
    df_all[skewed_features], output_distribution<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;normal&#39;</span>, copy<span style="color:#f92672">=</span>True)
</code></pre></div><pre><code>20 skewed numerical columns.
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Check again for the skewnesses of the numerical cols</span>
skewed_cols <span style="color:#f92672">=</span> df_all[numeric_cols]<span style="color:#f92672">.</span>apply(
    <span style="color:#66d9ef">lambda</span> col: skew(col))<span style="color:#f92672">.</span>sort_values(ascending<span style="color:#f92672">=</span>False)

skewness <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;Skewness&#39;</span>: skewed_cols})

skewness <span style="color:#f92672">=</span> skewness[abs(skewness[<span style="color:#e6db74">&#39;Skewness&#39;</span>]) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.75</span>]
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{skewness.shape[0]} skewed numerical columns.&#39;</span>)
</code></pre></div><pre><code>11 skewed numerical columns.
</code></pre>
<h2 id="encode-categorical-valuee">Encode categorical valuee</h2>
<p>Transform categorical cols by using <code>pd.get_dummies()</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(df_all<span style="color:#f92672">.</span>shape)
<span style="color:#75715e"># Column names in the DataFrame to be encoded. If columns is None then all the</span>
<span style="color:#75715e"># columns with object or category dtype will be converted.</span>
df_all <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>get_dummies(df_all)
<span style="color:#66d9ef">print</span>(df_all<span style="color:#f92672">.</span>shape)
</code></pre></div><pre><code>(2917, 79)
(2917, 330)
</code></pre>
<h1 id="training-and-testing">Training and testing</h1>
<h2 id="base-model">Base model</h2>
<p>Now we will start to train and test with a base model with default parameters
to see how it would perform as a base line.
Root-Mean-Squared-Error (RMSE) as the evaluation metric for the competition, the equation is:</p>
<p>$$\operatorname{RMSE}(y, \hat{y})=\sqrt{\frac{1}{n_{\text {samples }}} \sum_{i=0}^{n_{\text {symples }}-1}\left(y_{i}-\hat{y}_{i}\right)^{2}}$$.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Unpack training and testing data sets</span>
df_train <span style="color:#f92672">=</span> df_all[:len(ids_train)]<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;Id&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)
df_test <span style="color:#f92672">=</span> df_all[len(ids_train):]<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;Id&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;columns&#39;</span>)

X_train <span style="color:#f92672">=</span> df_train<span style="color:#f92672">.</span>values
X_test <span style="color:#f92672">=</span> df_test
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline
<span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> Lasso, ElasticNet, Ridge
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> cross_val_score
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_squared_error, make_scorer
<span style="color:#f92672">from</span> sklearn.compose <span style="color:#f92672">import</span> TransformedTargetRegressor
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> QuantileTransformer

Y_train_norm <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log1p(Y_train)

<span style="color:#75715e"># there&#39;s no implementation of RMSE in the scikit-learn library, so we have to</span>
<span style="color:#75715e"># define a scorer of RMSE</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rmse_cal</span>(y_true, y_pred):
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sqrt(mean_squared_error(y_true, y_pred))
    <span style="color:#75715e"># return np.sqrt(np.sum(np.square(y_pred - y_true)) / len(y_pred))</span>


<span style="color:#75715e"># if the custom score function is a loss (greater_is_better=False), the output</span>
<span style="color:#75715e"># of the python function is negated by the scorer object, conforming to the</span>
<span style="color:#75715e"># cross validation convention that scorers return higher values for better</span>
<span style="color:#75715e"># models.</span>
rmse <span style="color:#f92672">=</span> make_scorer(rmse_cal, greater_is_better<span style="color:#f92672">=</span>False)

<span style="color:#75715e"># ridgepip = Pipeline([</span>
    <span style="color:#75715e"># (&#39;tran&#39;, TransformedTargetRegressor(</span>
    <span style="color:#75715e">#     regressor=Lasso(), func=np.log1p, inverse_func=np.expm1)),</span>
    <span style="color:#75715e"># (&#39;tran&#39;, TransformedTargetRegressor(</span>
    <span style="color:#75715e">#     regressor=Ridge(), func=np.log1p, inverse_func=np.expm1)),</span>
<span style="color:#75715e"># ])</span>

models <span style="color:#f92672">=</span> [
    Lasso(),
    <span style="color:#75715e"># ridgepip,</span>
    <span style="color:#75715e"># # ElasticNet(),</span>
    Ridge(),
]

CV <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>
<span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> models:
    scores <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>cross_val_score(m, X_train, Y_train_norm,
                              scoring<span style="color:#f92672">=</span>rmse, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{type(m).__name__}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
          f<span style="color:#e6db74">&#39;Scores: {scores}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
          <span style="color:#75715e"># +/-std*2 for 95% confidence interval</span>
          f<span style="color:#e6db74">&#39;Accuracy: {scores.mean(): 0.4f} (+/-{scores.std() * 2: 0.4f})</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
          f<span style="color:#e6db74">&#39;{&#34;-&#34;*20}&#39;</span>)
</code></pre></div><pre><code>Lasso
Scores: [0.22425222 0.23934427 0.23998284 0.24165163 0.23227816]
Accuracy:  0.2355 (+/- 0.0129)
--------------------
Ridge
Scores: [0.11456344 0.12197379 0.13560006 0.1083432  0.1172416 ]
Accuracy:  0.1195 (+/- 0.0183)
--------------------
</code></pre>
<h2 id="gridsearch-for-best-model-with-best-parameters">GridSearch for best model with best parameters</h2>
<p>The base models give somehow good results. The CV RMSE score of the /Ridge/
model is around the top-1000 in the competition&rsquo;s leaderboard. Now let&rsquo;s try
to find the best parameters for these and other models with <code>GridSearchCV</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.svm <span style="color:#f92672">import</span> SVR
<span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> RobustScaler
<span style="color:#f92672">from</span> sklearn.kernel_ridge <span style="color:#f92672">import</span> KernelRidge
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split, GridSearchCV
<span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> GradientBoostingRegressor
<span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics


Y_train_norm <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log1p(Y_train)

X_train_cv, X_test_cv, Y_train_cv, Y_test_cv <span style="color:#f92672">=</span> train_test_split(
    X_train, Y_train_norm, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)


param_space <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;rob_lasso&#39;</span>: {
        <span style="color:#e6db74">&#39;model&#39;</span>: Pipeline([(<span style="color:#e6db74">&#39;sca&#39;</span>, RobustScaler()), (<span style="color:#e6db74">&#39;model&#39;</span>, Lasso())]),
        <span style="color:#e6db74">&#39;params&#39;</span>: {
            <span style="color:#e6db74">&#39;model__alpha&#39;</span>: [<span style="color:#ae81ff">0.00005</span>, <span style="color:#ae81ff">0.0004</span>, <span style="color:#ae81ff">0.0005</span>, <span style="color:#ae81ff">0.0007</span>, <span style="color:#ae81ff">0.005</span>, <span style="color:#ae81ff">0.05</span>, <span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1</span>],
        }
    },
    <span style="color:#e6db74">&#39;ridge&#39;</span>: {
        <span style="color:#e6db74">&#39;model&#39;</span>: Ridge(),
        <span style="color:#e6db74">&#39;params&#39;</span>: {
            <span style="color:#e6db74">&#39;alpha&#39;</span>: [<span style="color:#ae81ff">1e-3</span>, <span style="color:#ae81ff">1e-2</span>, <span style="color:#ae81ff">1e-1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>],
        }
    },
    <span style="color:#e6db74">&#39;kernel_ridge&#39;</span>: {
        <span style="color:#e6db74">&#39;model&#39;</span>: KernelRidge(),
        <span style="color:#e6db74">&#39;params&#39;</span>: {
            <span style="color:#e6db74">&#39;alpha&#39;</span>: [<span style="color:#ae81ff">1e-3</span>, <span style="color:#ae81ff">1e-2</span>, <span style="color:#ae81ff">1e-1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>],
        }
    },
    <span style="color:#e6db74">&#39;elastic_net&#39;</span>: {
        <span style="color:#e6db74">&#39;model&#39;</span>: Pipeline([(<span style="color:#e6db74">&#39;sca&#39;</span>, RobustScaler()), (<span style="color:#e6db74">&#39;model&#39;</span>, ElasticNet())]),
        <span style="color:#e6db74">&#39;params&#39;</span>: {
            <span style="color:#e6db74">&#39;model__alpha&#39;</span>: [<span style="color:#ae81ff">0.00005</span>, <span style="color:#ae81ff">0.0004</span>, <span style="color:#ae81ff">0.0005</span>, <span style="color:#ae81ff">0.0007</span>, <span style="color:#ae81ff">0.005</span>, <span style="color:#ae81ff">0.05</span>, <span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1</span>],
            <span style="color:#75715e"># Note that a good choice of list of values for l1_ratio is often to</span>
            <span style="color:#75715e"># put more values close to 1 (i.e. Lasso) and less close to 0 (i.e.</span>
            <span style="color:#75715e"># Ridge)</span>
            <span style="color:#e6db74">&#39;model__l1_ratio&#39;</span>: [<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">5</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">7</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">75</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">8</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">85</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">9</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">95</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">97</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">99</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">995</span>, <span style="color:#ae81ff">1</span>],
        }
    },
    <span style="color:#75715e"># &#39;gboost&#39;: {</span>
    <span style="color:#75715e">#     &#39;model&#39;: GradientBoostingRegressor(),</span>
    <span style="color:#75715e">#     &#39;params&#39;: {</span>
    <span style="color:#75715e">#         &#39;loss&#39;: [&#39;ls&#39;, &#39;lad&#39;, &#39;huber&#39;, &#39;quantile&#39;],</span>
    <span style="color:#75715e">#         &#39;learning_rate&#39;: [0.01, 0.1],</span>
    <span style="color:#75715e">#         &#39;n_estimators&#39;: [100, 500, 1000, 3000],</span>
    <span style="color:#75715e">#         &#39;max_depth&#39;: [2, 3, 4],</span>
    <span style="color:#75715e">#         &#39;min_samples_split&#39;: [2, 5, 10],</span>
    <span style="color:#75715e">#     }</span>
    <span style="color:#75715e"># },</span>
    <span style="color:#75715e"># &#39;svr&#39;: {</span>
    <span style="color:#75715e">#     &#39;model&#39;: SVR(),</span>
    <span style="color:#75715e">#     &#39;params&#39;: {</span>
    <span style="color:#75715e">#         &#39;kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;],</span>
    <span style="color:#75715e">#         &#39;C&#39;: [1, 10],</span>
    <span style="color:#75715e">#     }</span>
    <span style="color:#75715e"># },</span>
}

gs_rec <span style="color:#f92672">=</span> []

<span style="color:#75715e"># grid search parameters</span>
<span style="color:#66d9ef">for</span> name, pair <span style="color:#f92672">in</span> param_space<span style="color:#f92672">.</span>items():
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{name}---------------&#39;</span>)
    gs_rg <span style="color:#f92672">=</span> GridSearchCV(pair[<span style="color:#e6db74">&#39;model&#39;</span>], pair[<span style="color:#e6db74">&#39;params&#39;</span>],
                         scoring<span style="color:#f92672">=</span>rmse, cv<span style="color:#f92672">=</span>CV, error_score<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
    gs_rg<span style="color:#f92672">.</span>fit(X_train, Y_train_norm)
    <span style="color:#66d9ef">print</span>(gs_rg<span style="color:#f92672">.</span>best_params_)
    <span style="color:#66d9ef">print</span>(gs_rg<span style="color:#f92672">.</span>best_score_)

    gs_rg_cv <span style="color:#f92672">=</span> GridSearchCV(pair[<span style="color:#e6db74">&#39;model&#39;</span>], pair[<span style="color:#e6db74">&#39;params&#39;</span>],
                            scoring<span style="color:#f92672">=</span>rmse, cv<span style="color:#f92672">=</span>CV, error_score<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
    gs_rg_cv<span style="color:#f92672">.</span>fit(X_train_cv, Y_train_cv)
    pred_test <span style="color:#f92672">=</span> gs_rg_cv<span style="color:#f92672">.</span>predict(X_test_cv)
    y_score <span style="color:#f92672">=</span> rmse_cal(Y_test_cv, pred_test)

    <span style="color:#66d9ef">print</span>(gs_rg_cv<span style="color:#f92672">.</span>best_params_)
    <span style="color:#66d9ef">print</span>(gs_rg_cv<span style="color:#f92672">.</span>best_score_)
    <span style="color:#66d9ef">print</span>(y_score)

    gs_rec<span style="color:#f92672">.</span>append({
        <span style="color:#e6db74">&#39;name&#39;</span>: name,
        <span style="color:#e6db74">&#39;params&#39;</span>: gs_rg<span style="color:#f92672">.</span>best_params_,
        <span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#f92672">-</span>gs_rg<span style="color:#f92672">.</span>best_score_,
        <span style="color:#e6db74">&#39;cv_test_params&#39;</span>: gs_rg_cv<span style="color:#f92672">.</span>best_params_,
        <span style="color:#e6db74">&#39;cv_test_score&#39;</span>: y_score
    })

df_gs <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(gs_rec, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;name&#39;</span>, <span style="color:#e6db74">&#39;score&#39;</span>, <span style="color:#e6db74">&#39;params&#39;</span>,
                                      <span style="color:#e6db74">&#39;cv_test_score&#39;</span>, <span style="color:#e6db74">&#39;cv_test_params&#39;</span>]
                     )<span style="color:#f92672">.</span>sort_values(by<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;score&#39;</span>, <span style="color:#e6db74">&#39;cv_test_score&#39;</span>])
df_gs
</code></pre></div><pre><code>rob_lasso---------------
{'model__alpha': 0.0005}
-0.1108321642082426
{'model__alpha': 0.0005}
-0.11385591248537665
0.1092651116732159
ridge---------------
{'alpha': 10}
-0.11417733254437629
{'alpha': 10}
-0.11723423641202352
0.11022009984391984
kernel_ridge---------------
{'alpha': 10}
-0.11675117173959225
{'alpha': 10}
-0.1209044169077714
0.11171230919473786
elastic_net---------------
{'model__alpha': 0.0005, 'model__l1_ratio': 0.9}
-0.11081242246612653
{'model__alpha': 0.0007, 'model__l1_ratio': 0.8}
-0.1138195082928615
0.10934894252124043
</code></pre>
<!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<p>Now let&rsquo;s Train with the best model so far and predict on the test data. As
aforementioned, the values of &lsquo;SalePrice&rsquo; does fall in a normal distribution.
So we&rsquo;ll transform the target values by <code>QuantileTransformer</code> and
<code>TransformedTargetRegressor</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> datetime <span style="color:#f92672">import</span> datetime


<span style="color:#75715e"># model = Pipeline(</span>
<span style="color:#75715e">#     [(&#39;sca&#39;, RobustScaler()), (&#39;model&#39;, TransformedTargetRegressor(</span>
<span style="color:#75715e">#         regressor=ElasticNet(alpha=0.0005, l1_ratio=0.85), func=np.log1p, inverse_func=np.expm1))])</span>
model <span style="color:#f92672">=</span> Pipeline(
    [(<span style="color:#e6db74">&#39;sca&#39;</span>, RobustScaler()), (<span style="color:#e6db74">&#39;model&#39;</span>, TransformedTargetRegressor(
        regressor<span style="color:#f92672">=</span>ElasticNet(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0005</span>, l1_ratio<span style="color:#f92672">=</span><span style="color:#ae81ff">0.85</span>),
        <span style="color:#75715e"># regressor=Lasso(alpha=0.0005),</span>
        transformer<span style="color:#f92672">=</span>QuantileTransformer(output_distribution<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;normal&#39;</span>)))])

model<span style="color:#f92672">.</span>fit(X_train, Y_train)

pred <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">submit</span>(ids, pred, suffix):
    sub <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame()
    sub[<span style="color:#e6db74">&#39;Id&#39;</span>] <span style="color:#f92672">=</span> ids_test
    sub[<span style="color:#e6db74">&#39;SalePrice&#39;</span>] <span style="color:#f92672">=</span> pred
    timestamp <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()<span style="color:#f92672">.</span>strftime(<span style="color:#e6db74">&#39;%Y-%m-</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">_%H-%M-%S&#39;</span>)
    <span style="color:#75715e"># sub.to_csv(</span>
    <span style="color:#75715e"># f&#39;result/kaggle1_sub_{suffix}_{score:.5f}.csv&#39;, index=False)</span>
    sub<span style="color:#f92672">.</span>to_csv(
        f<span style="color:#e6db74">&#39;submissions/{suffix}_{timestamp}.csv.gz&#39;</span>, index<span style="color:#f92672">=</span>False,
        compression<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gzip&#39;</span>)


submit(ids_test, pred, <span style="color:#e6db74">&#39;elastic_net&#39;</span>)
</code></pre></div>
    </div>

    


    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/machine-learning/">Machine Learning</a>
  
  <a class="badge badge-light" href="/tags/regression/">Regression</a>
  
</div>



    
      








  






  
  
  
    
  
  
  <div class="media author-card">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_huf79fbb756ad93d32a2794d68e8fd33ec_47015_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://pcx.linkedinfo.co/">PENG, Cong</a></h5>
      <h6 class="card-subtitle">Ph.D. Student</h6>
      
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
          <li>
            <a href="mailto:cong.peng@bth.se" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a href="https://scholar.google.com/citations?user=87g_0KgAAAAJ" target="_blank" rel="noopener">
              <i class="ai ai-google-scholar"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a href="https://www.researchgate.net/profile/Cong_Peng5" target="_blank" rel="noopener">
              <i class="fab fa-researchgate"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a href="https://github.com/ddxgz" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/project/linkedinfo/">LinkedInfo.co</a></li>
          
        </ul>
      </div>
      
    

    

    


  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.130521ecfc6f534c52c158217bbff718.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    ©2014–2019 Cong Peng &middot; 

    Powered by
    <a href="https://orgmode.org/" target="_blank" rel="noopener">Org-mode</a> and the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
