<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Text classification | Cong Peng</title>
    <link>https://pcx.linkedinfo.co/tags/text-classification/</link>
      <atom:link href="https://pcx.linkedinfo.co/tags/text-classification/index.xml" rel="self" type="application/rss+xml" />
    <description>Text classification</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>©2014–2019 Cong Peng</copyright><lastBuildDate>Thu, 13 Feb 2020 11:20:19 +0200</lastBuildDate>
    <image>
      <url>https://pcx.linkedinfo.co/img/icon-192.png</url>
      <title>Text classification</title>
      <link>https://pcx.linkedinfo.co/tags/text-classification/</link>
    </image>
    
    <item>
      <title>Using BERT to perform Topic Tag Prediction for Technical Articles</title>
      <link>https://pcx.linkedinfo.co/post/text-tag-prediction-bert/</link>
      <pubDate>Thu, 13 Feb 2020 11:20:19 +0200</pubDate>
      <guid>https://pcx.linkedinfo.co/post/text-tag-prediction-bert/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;This is a follow up post of &lt;a href=&#34;https://pcx.linkedinfo.co/post/text-tag-prediction/&#34; target=&#34;_blank&#34;&gt;Multi-label classification to predict topic tags of technical articles from LinkedInfo.co&lt;/a&gt;. We will continute the same task by using BERT.&lt;/p&gt;

&lt;p&gt;Firstly we&amp;rsquo;ll just use the embeddings from BERT, and then feed them to the same classification model used in the last post, SVM with linear kenel. The reason of keep using SVM is that the size of the dataset is quite small.&lt;/p&gt;

&lt;h1 id=&#34;experiments&#34;&gt;Experiments&lt;/h1&gt;

&lt;h2 id=&#34;classify-by-using-bert-mini-and-svm-with-linear-kernel&#34;&gt;Classify by using BERT-Mini and SVM with Linear Kernel&lt;/h2&gt;

&lt;p&gt;Due to the limited computation capacity, we&amp;rsquo;ll use a smaller BERT model - BERT-Mini. The first experiment we&amp;rsquo;ll try to train on only the titles of the articles.&lt;/p&gt;

&lt;p&gt;Now we firstly load the dataset. And then load the pretrained BERT tokenizer and model. Note that we only load the article samples that are in English since the BERT-Mini model here were pretrained in English.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import os
from collections import Counter

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler
import nltk
import plotly.express as px
from transformers import (BertPreTrainedModel, AutoTokenizer, AutoModel,
                          BertForSequenceClassification, AdamW, BertModel,
                          BertTokenizer, BertConfig, get_linear_schedule_with_warmup)

import dataset
from mltb.bert import bert_tokenize, bert_transform, get_tokenizer_model, download_once_pretrained_transformers
from mltb.experiment import multilearn_iterative_train_test_split
from mltb.metrics import classification_report_avg


nltk.download(&#39;punkt&#39;)

RAND_STATE = 20200122
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ds = dataset.ds_info_tags(from_batch_cache=&#39;info&#39;, lan=&#39;en&#39;,
                          concate_title=True,
                          filter_tags_threshold=0, partial_len=3000)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;c = Counter([tag for tags in ds.target_decoded for tag in tags])

dfc = pd.DataFrame.from_dict(c, orient=&#39;index&#39;, columns=[&#39;count&#39;]).sort_values(by=&#39;count&#39;, ascending=False)[:100]

fig_Y = px.bar(dfc, x=dfc.index, y=&#39;count&#39;,
               text=&#39;count&#39;,
               labels={&#39;count&#39;: &#39;Number of infos&#39;,
                       &#39;x&#39;: &#39;Tags&#39;})
fig_Y.update_traces(texttemplate=&#39;%{text}&#39;)
&lt;/code&gt;&lt;/pre&gt;



&lt;html&gt;
&lt;head&gt;&lt;meta charset=&#34;utf-8&#34; /&gt;&lt;/head&gt;
&lt;body&gt;
    &lt;div&gt;
            &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text/javascript&#34;&gt;if (window.MathJax) {MathJax.Hub.Config({SVG: {font: &#34;STIX-Web&#34;}});}&lt;/script&gt;
                &lt;script type=&#34;text/javascript&#34;&gt;window.PlotlyConfig = {MathJaxConfig: &#39;local&#39;};&lt;/script&gt;
        &lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;    
            &lt;div id=&#34;d7db1ccb-6f97-4d35-a5b0-eda705ab1bdb&#34; class=&#34;plotly-graph-div&#34; style=&#34;height:525px; width:100%;&#34;&gt;&lt;/div&gt;
            &lt;script type=&#34;text/javascript&#34;&gt;
                
                    window.PLOTLYENV=window.PLOTLYENV || {};
                    
                if (document.getElementById(&#34;d7db1ccb-6f97-4d35-a5b0-eda705ab1bdb&#34;)) {
                    Plotly.newPlot(
                        &#39;d7db1ccb-6f97-4d35-a5b0-eda705ab1bdb&#39;,
                        [{&#34;alignmentgroup&#34;: &#34;True&#34;, &#34;hoverlabel&#34;: {&#34;namelength&#34;: 0}, &#34;hovertemplate&#34;: &#34;Tags=%{x}&lt;br&gt;Number of infos=%{text}&#34;, &#34;legendgroup&#34;: &#34;&#34;, &#34;marker&#34;: {&#34;color&#34;: &#34;#636efa&#34;}, &#34;name&#34;: &#34;&#34;, &#34;offsetgroup&#34;: &#34;&#34;, &#34;orientation&#34;: &#34;v&#34;, &#34;showlegend&#34;: false, &#34;text&#34;: [425.0, 272.0, 181.0, 155.0, 129.0, 89.0, 80.0, 77.0, 67.0, 60.0, 53.0, 50.0, 48.0, 47.0, 42.0, 39.0, 39.0, 39.0, 35.0, 35.0, 33.0, 32.0, 32.0, 32.0, 31.0, 31.0, 31.0, 31.0, 30.0, 29.0, 28.0, 27.0, 27.0, 26.0, 26.0, 25.0, 25.0, 25.0, 22.0, 22.0, 21.0, 20.0, 19.0, 19.0, 19.0, 18.0, 18.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 15.0, 15.0, 15.0, 15.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], &#34;textposition&#34;: &#34;auto&#34;, &#34;texttemplate&#34;: &#34;%{text}&#34;, &#34;type&#34;: &#34;bar&#34;, &#34;x&#34;: [&#34;python&#34;, &#34;golang&#34;, &#34;web&#34;, &#34;javascript&#34;, &#34;machine-learning&#34;, &#34;microservices&#34;, &#34;deep-learning&#34;, &#34;neural-networks&#34;, &#34;api&#34;, &#34;data-science&#34;, &#34;java&#34;, &#34;node.js&#34;, &#34;testing&#34;, &#34;concurrency&#34;, &#34;vue.js&#34;, &#34;db&#34;, &#34;system-architecture&#34;, &#34;react&#34;, &#34;compiler&#34;, &#34;docker&#34;, &#34;http&#34;, &#34;kubernetes&#34;, &#34;rust&#34;, &#34;git&#34;, &#34;django&#34;, &#34;restful&#34;, &#34;cpp&#34;, &#34;data-visualization&#34;, &#34;nlp&#34;, &#34;oop&#34;, &#34;kafka&#34;, &#34;angular&#34;, &#34;graphql&#34;, &#34;linux&#34;, &#34;programming&#34;, &#34;css&#34;, &#34;frontend&#34;, &#34;security&#34;, &#34;interpreter&#34;, &#34;functional-programming&#34;, &#34;distributed-system&#34;, &#34;chatbot&#34;, &#34;c&#34;, &#34;r&#34;, &#34;ai&#34;, &#34;mysql&#34;, &#34;http2&#34;, &#34;debug&#34;, &#34;tensorflow&#34;, &#34;asyncio&#34;, &#34;tdd&#34;, &#34;pandas&#34;, &#34;error-handling&#34;, &#34;memory&#34;, &#34;performance&#34;, &#34;algorithm&#34;, &#34;semantic-web&#34;, &#34;emacs&#34;, &#34;auth&#34;, &#34;grpc&#34;, &#34;computer-vision&#34;, &#34;pascal&#34;, &#34;statistics&#34;, &#34;redis&#34;, &#34;big-data&#34;, &#34;numpy&#34;, &#34;postgres&#34;, &#34;refactoring&#34;, &#34;mongodb&#34;, &#34;programmer-development&#34;, &#34;data-structure&#34;, &#34;pwa&#34;, &#34;finance&#34;, &#34;graphdb&#34;, &#34;asynchronous&#34;, &#34;json&#34;, &#34;cloud-computing&#34;, &#34;web-scraping&#34;, &#34;html&#34;, &#34;spark&#34;, &#34;blockchain&#34;, &#34;webpack&#34;, &#34;vim&#34;, &#34;dotnet&#34;, &#34;jwt&#34;, &#34;sql&#34;, &#34;stock&#34;, &#34;csharp&#34;, &#34;log&#34;, &#34;lxc&#34;, &#34;kotlin&#34;, &#34;storage&#34;, &#34;multithreading&#34;, &#34;scala&#34;, &#34;interface&#34;, &#34;spring&#34;, &#34;jit&#34;, &#34;flask&#34;, &#34;design-pattern&#34;, &#34;websocket&#34;], &#34;xaxis&#34;: &#34;x&#34;, &#34;y&#34;: [425, 272, 181, 155, 129, 89, 80, 77, 67, 60, 53, 50, 48, 47, 42, 39, 39, 39, 35, 35, 33, 32, 32, 32, 31, 31, 31, 31, 30, 29, 28, 27, 27, 26, 26, 25, 25, 25, 22, 22, 21, 20, 19, 19, 19, 18, 18, 17, 17, 17, 16, 16, 16, 16, 15, 15, 15, 15, 14, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8], &#34;yaxis&#34;: &#34;y&#34;}],
                        {&#34;barmode&#34;: &#34;relative&#34;, &#34;legend&#34;: {&#34;tracegroupgap&#34;: 0}, &#34;margin&#34;: {&#34;t&#34;: 60}, &#34;template&#34;: {&#34;data&#34;: {&#34;bar&#34;: [{&#34;error_x&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;error_y&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;marker&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#E5ECF6&#34;, &#34;width&#34;: 0.5}}, &#34;type&#34;: &#34;bar&#34;}], &#34;barpolar&#34;: [{&#34;marker&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#E5ECF6&#34;, &#34;width&#34;: 0.5}}, &#34;type&#34;: &#34;barpolar&#34;}], &#34;carpet&#34;: [{&#34;aaxis&#34;: {&#34;endlinecolor&#34;: &#34;#2a3f5f&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;minorgridcolor&#34;: &#34;white&#34;, &#34;startlinecolor&#34;: &#34;#2a3f5f&#34;}, &#34;baxis&#34;: {&#34;endlinecolor&#34;: &#34;#2a3f5f&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;minorgridcolor&#34;: &#34;white&#34;, &#34;startlinecolor&#34;: &#34;#2a3f5f&#34;}, &#34;type&#34;: &#34;carpet&#34;}], &#34;choropleth&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;choropleth&#34;}], &#34;contour&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;contour&#34;}], &#34;contourcarpet&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;contourcarpet&#34;}], &#34;heatmap&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;heatmap&#34;}], &#34;heatmapgl&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;heatmapgl&#34;}], &#34;histogram&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;histogram&#34;}], &#34;histogram2d&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;histogram2d&#34;}], &#34;histogram2dcontour&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;histogram2dcontour&#34;}], &#34;mesh3d&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;mesh3d&#34;}], &#34;parcoords&#34;: [{&#34;line&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;parcoords&#34;}], &#34;pie&#34;: [{&#34;automargin&#34;: true, &#34;type&#34;: &#34;pie&#34;}], &#34;scatter&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatter&#34;}], &#34;scatter3d&#34;: [{&#34;line&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatter3d&#34;}], &#34;scattercarpet&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattercarpet&#34;}], &#34;scattergeo&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattergeo&#34;}], &#34;scattergl&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattergl&#34;}], &#34;scattermapbox&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattermapbox&#34;}], &#34;scatterpolar&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterpolar&#34;}], &#34;scatterpolargl&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterpolargl&#34;}], &#34;scatterternary&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterternary&#34;}], &#34;surface&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;surface&#34;}], &#34;table&#34;: [{&#34;cells&#34;: {&#34;fill&#34;: {&#34;color&#34;: &#34;#EBF0F8&#34;}, &#34;line&#34;: {&#34;color&#34;: &#34;white&#34;}}, &#34;header&#34;: {&#34;fill&#34;: {&#34;color&#34;: &#34;#C8D4E3&#34;}, &#34;line&#34;: {&#34;color&#34;: &#34;white&#34;}}, &#34;type&#34;: &#34;table&#34;}]}, &#34;layout&#34;: {&#34;annotationdefaults&#34;: {&#34;arrowcolor&#34;: &#34;#2a3f5f&#34;, &#34;arrowhead&#34;: 0, &#34;arrowwidth&#34;: 1}, &#34;coloraxis&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;colorscale&#34;: {&#34;diverging&#34;: [[0, &#34;#8e0152&#34;], [0.1, &#34;#c51b7d&#34;], [0.2, &#34;#de77ae&#34;], [0.3, &#34;#f1b6da&#34;], [0.4, &#34;#fde0ef&#34;], [0.5, &#34;#f7f7f7&#34;], [0.6, &#34;#e6f5d0&#34;], [0.7, &#34;#b8e186&#34;], [0.8, &#34;#7fbc41&#34;], [0.9, &#34;#4d9221&#34;], [1, &#34;#276419&#34;]], &#34;sequential&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;sequentialminus&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]]}, &#34;colorway&#34;: [&#34;#636efa&#34;, &#34;#EF553B&#34;, &#34;#00cc96&#34;, &#34;#ab63fa&#34;, &#34;#FFA15A&#34;, &#34;#19d3f3&#34;, &#34;#FF6692&#34;, &#34;#B6E880&#34;, &#34;#FF97FF&#34;, &#34;#FECB52&#34;], &#34;font&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;geo&#34;: {&#34;bgcolor&#34;: &#34;white&#34;, &#34;lakecolor&#34;: &#34;white&#34;, &#34;landcolor&#34;: &#34;#E5ECF6&#34;, &#34;showlakes&#34;: true, &#34;showland&#34;: true, &#34;subunitcolor&#34;: &#34;white&#34;}, &#34;hoverlabel&#34;: {&#34;align&#34;: &#34;left&#34;}, &#34;hovermode&#34;: &#34;closest&#34;, &#34;mapbox&#34;: {&#34;style&#34;: &#34;light&#34;}, &#34;paper_bgcolor&#34;: &#34;white&#34;, &#34;plot_bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;polar&#34;: {&#34;angularaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;radialaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}}, &#34;scene&#34;: {&#34;xaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}, &#34;yaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}, &#34;zaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}}, &#34;shapedefaults&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}}, &#34;ternary&#34;: {&#34;aaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;baxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;caxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}}, &#34;title&#34;: {&#34;x&#34;: 0.05}, &#34;xaxis&#34;: {&#34;automargin&#34;: true, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;, &#34;title&#34;: {&#34;standoff&#34;: 15}, &#34;zerolinecolor&#34;: &#34;white&#34;, &#34;zerolinewidth&#34;: 2}, &#34;yaxis&#34;: {&#34;automargin&#34;: true, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;, &#34;title&#34;: {&#34;standoff&#34;: 15}, &#34;zerolinecolor&#34;: &#34;white&#34;, &#34;zerolinewidth&#34;: 2}}}, &#34;xaxis&#34;: {&#34;anchor&#34;: &#34;y&#34;, &#34;domain&#34;: [0.0, 1.0], &#34;title&#34;: {&#34;text&#34;: &#34;Tags&#34;}}, &#34;yaxis&#34;: {&#34;anchor&#34;: &#34;x&#34;, &#34;domain&#34;: [0.0, 1.0], &#34;title&#34;: {&#34;text&#34;: &#34;Number of infos&#34;}}},
                        {&#34;responsive&#34;: true}
                    ).then(function(){
                            
var gd = document.getElementById(&#39;d7db1ccb-6f97-4d35-a5b0-eda705ab1bdb&#39;);
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === &#39;none&#39;) {{
            console.log([gd, &#39;removed!&#39;]);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest(&#39;#notebook-container&#39;);
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest(&#39;.output&#39;);
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })
                };
                
            &lt;/script&gt;
        &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;


&lt;pre&gt;&lt;code&gt;dfc_tail = pd.DataFrame.from_dict(c, orient=&#39;index&#39;, columns=[&#39;count&#39;]).sort_values(by=&#39;count&#39;, ascending=False)[-200:]

fig_Y = px.bar(dfc_tail, x=dfc_tail.index, y=&#39;count&#39;,
               text=&#39;count&#39;,
               labels={&#39;count&#39;: &#39;Number of infos&#39;,
                       &#39;x&#39;: &#39;Tags&#39;})
fig_Y.update_traces(texttemplate=&#39;%{text}&#39;)
&lt;/code&gt;&lt;/pre&gt;



&lt;html&gt;
&lt;head&gt;&lt;meta charset=&#34;utf-8&#34; /&gt;&lt;/head&gt;
&lt;body&gt;
    &lt;div&gt;
            &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text/javascript&#34;&gt;if (window.MathJax) {MathJax.Hub.Config({SVG: {font: &#34;STIX-Web&#34;}});}&lt;/script&gt;
                &lt;script type=&#34;text/javascript&#34;&gt;window.PlotlyConfig = {MathJaxConfig: &#39;local&#39;};&lt;/script&gt;
        &lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;    
            &lt;div id=&#34;93a29e39-9a0c-49f1-9585-5d6ba50f38f5&#34; class=&#34;plotly-graph-div&#34; style=&#34;height:525px; width:100%;&#34;&gt;&lt;/div&gt;
            &lt;script type=&#34;text/javascript&#34;&gt;
                
                    window.PLOTLYENV=window.PLOTLYENV || {};
                    
                if (document.getElementById(&#34;93a29e39-9a0c-49f1-9585-5d6ba50f38f5&#34;)) {
                    Plotly.newPlot(
                        &#39;93a29e39-9a0c-49f1-9585-5d6ba50f38f5&#39;,
                        [{&#34;alignmentgroup&#34;: &#34;True&#34;, &#34;hoverlabel&#34;: {&#34;namelength&#34;: 0}, &#34;hovertemplate&#34;: &#34;Tags=%{x}&lt;br&gt;Number of infos=%{text}&#34;, &#34;legendgroup&#34;: &#34;&#34;, &#34;marker&#34;: {&#34;color&#34;: &#34;#636efa&#34;}, &#34;name&#34;: &#34;&#34;, &#34;offsetgroup&#34;: &#34;&#34;, &#34;orientation&#34;: &#34;v&#34;, &#34;showlegend&#34;: false, &#34;text&#34;: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], &#34;textposition&#34;: &#34;auto&#34;, &#34;texttemplate&#34;: &#34;%{text}&#34;, &#34;type&#34;: &#34;bar&#34;, &#34;x&#34;: [&#34;fusion.js&#34;, &#34;load-balance&#34;, &#34;ethic&#34;, &#34;web-services&#34;, &#34;aws&#34;, &#34;filesystem&#34;, &#34;iot&#34;, &#34;emacs-lisp&#34;, &#34;github&#34;, &#34;crawler&#34;, &#34;event-driven&#34;, &#34;pytorch&#34;, &#34;pdf&#34;, &#34;lambda&#34;, &#34;spacemacs&#34;, &#34;pdb&#34;, &#34;namespaces&#34;, &#34;mvc&#34;, &#34;unicode&#34;, &#34;sdk&#34;, &#34;makefile&#34;, &#34;webkit&#34;, &#34;cdn&#34;, &#34;object-detection&#34;, &#34;documentation&#34;, &#34;project-management&#34;, &#34;cloud&#34;, &#34;classification&#34;, &#34;jvm&#34;, &#34;circuit-breaker&#34;, &#34;integration-test&#34;, &#34;amqp&#34;, &#34;anomaly-detection&#34;, &#34;dom&#34;, &#34;cloud-storage&#34;, &#34;ddd&#34;, &#34;vue-router&#34;, &#34;activemq&#34;, &#34;excel&#34;, &#34;linked-list&#34;, &#34;linear-programming&#34;, &#34;electron&#34;, &#34;kernel&#34;, &#34;lock-free&#34;, &#34;data-mining&#34;, &#34;virtual-machine&#34;, &#34;d3&#34;, &#34;neo4j&#34;, &#34;text-editor&#34;, &#34;unity&#34;, &#34;baas&#34;, &#34;information-theory&#34;, &#34;messaging&#34;, &#34;crdt&#34;, &#34;os&#34;, &#34;webgl&#34;, &#34;anti-pattern&#34;, &#34;hadoop&#34;, &#34;development&#34;, &#34;orm&#34;, &#34;voltdb&#34;, &#34;linear-model&#34;, &#34;consul&#34;, &#34;ansible&#34;, &#34;pathfinding&#34;, &#34;linked-data&#34;, &#34;ajax&#34;, &#34;rendering-techniques&#34;, &#34;random-forests&#34;, &#34;photography&#34;, &#34;dns&#34;, &#34;code-review&#34;, &#34;rsa&#34;, &#34;bloom-filter&#34;, &#34;deployment&#34;, &#34;forward+&#34;, &#34;token&#34;, &#34;gcc&#34;, &#34;oracle&#34;, &#34;cap&#34;, &#34;severless&#34;, &#34;wpf&#34;, &#34;graphics&#34;, &#34;cors&#34;, &#34;locale&#34;, &#34;ipv6&#34;, &#34;apache&#34;, &#34;iots&#34;, &#34;bytecode&#34;, &#34;cookie&#34;, &#34;bot&#34;, &#34;time-series-analysis&#34;, &#34;assembly&#34;, &#34;arm&#34;, &#34;multiprocessing&#34;, &#34;cms&#34;, &#34;cassandra&#34;, &#34;ggplot&#34;, &#34;mesos&#34;, &#34;automl&#34;, &#34;auditing&#34;, &#34;service-architecture&#34;, &#34;goroutine&#34;, &#34;text-generator&#34;, &#34;option&#34;, &#34;travis-ci&#34;, &#34;gateway&#34;, &#34;productivity&#34;, &#34;angularjs&#34;, &#34;pyspark&#34;, &#34;data-pipeline&#34;, &#34;raspberry-pi&#34;, &#34;service-mesh&#34;, &#34;memcached&#34;, &#34;quantum-communication&#34;, &#34;soa&#34;, &#34;ssh&#34;, &#34;open-data&#34;, &#34;command-line-interface&#34;, &#34;yaml&#34;, &#34;server&#34;, &#34;mac&#34;, &#34;monitoring&#34;, &#34;translation&#34;, &#34;posix&#34;, &#34;data-analytics&#34;, &#34;hdfs&#34;, &#34;recurrent-neural-networks&#34;, &#34;word-embedding&#34;, &#34;ludwig&#34;, &#34;image-recognition&#34;, &#34;maven&#34;, &#34;wordpress&#34;, &#34;elm&#34;, &#34;monad&#34;, &#34;plotly&#34;, &#34;math&#34;, &#34;protobuf&#34;, &#34;face-recognition&#34;, &#34;paxos&#34;, &#34;academia&#34;, &#34;speech-recognition&#34;, &#34;feature-engineering&#34;, &#34;babel&#34;, &#34;tachyon&#34;, &#34;postgresql&#34;, &#34;relational-database&#34;, &#34;data-workflow&#34;, &#34;monkey-patch&#34;, &#34;udp&#34;, &#34;ehealth&#34;, &#34;optimization&#34;, &#34;webrtc&#34;, &#34;proxy&#34;, &#34;cross-validation&#34;, &#34;hypothesis-test&#34;, &#34;ivy&#34;, &#34;markov-chains&#34;, &#34;text-recognition&#34;, &#34;latex&#34;, &#34;openstack&#34;, &#34;sqlite&#34;, &#34;computer-system&#34;, &#34;eslint&#34;, &#34;obect-detection&#34;, &#34;bokeh&#34;, &#34;data-cleaning&#34;, &#34;color-topics&#34;, &#34;firebase&#34;, &#34;doom-emacs&#34;, &#34;speech--recognition&#34;, &#34;decentralized-web&#34;, &#34;tkinter&#34;, &#34;ops&#34;, &#34;epoll&#34;, &#34;index&#34;, &#34;lua&#34;, &#34;dgraph&#34;, &#34;desktop&#34;, &#34;reliability&#34;, &#34;laravel&#34;, &#34;mypy&#34;, &#34;access-control&#34;, &#34;virtualization&#34;, &#34;kvm&#34;, &#34;qemu&#34;, &#34;csrf&#34;, &#34;quantum-computing&#34;, &#34;nodejs&#34;, &#34;random-forest&#34;, &#34;quantum-theory&#34;, &#34;socket&#34;, &#34;redux&#34;, &#34;ide&#34;, &#34;postgre&#34;, &#34;text-classifier&#34;, &#34;etl&#34;, &#34;cloud-native&#34;, &#34;agile&#34;, &#34;sparql&#34;], &#34;xaxis&#34;: &#34;x&#34;, &#34;y&#34;: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], &#34;yaxis&#34;: &#34;y&#34;}],
                        {&#34;barmode&#34;: &#34;relative&#34;, &#34;legend&#34;: {&#34;tracegroupgap&#34;: 0}, &#34;margin&#34;: {&#34;t&#34;: 60}, &#34;template&#34;: {&#34;data&#34;: {&#34;bar&#34;: [{&#34;error_x&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;error_y&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;marker&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#E5ECF6&#34;, &#34;width&#34;: 0.5}}, &#34;type&#34;: &#34;bar&#34;}], &#34;barpolar&#34;: [{&#34;marker&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#E5ECF6&#34;, &#34;width&#34;: 0.5}}, &#34;type&#34;: &#34;barpolar&#34;}], &#34;carpet&#34;: [{&#34;aaxis&#34;: {&#34;endlinecolor&#34;: &#34;#2a3f5f&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;minorgridcolor&#34;: &#34;white&#34;, &#34;startlinecolor&#34;: &#34;#2a3f5f&#34;}, &#34;baxis&#34;: {&#34;endlinecolor&#34;: &#34;#2a3f5f&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;minorgridcolor&#34;: &#34;white&#34;, &#34;startlinecolor&#34;: &#34;#2a3f5f&#34;}, &#34;type&#34;: &#34;carpet&#34;}], &#34;choropleth&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;choropleth&#34;}], &#34;contour&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;contour&#34;}], &#34;contourcarpet&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;contourcarpet&#34;}], &#34;heatmap&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;heatmap&#34;}], &#34;heatmapgl&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;heatmapgl&#34;}], &#34;histogram&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;histogram&#34;}], &#34;histogram2d&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;histogram2d&#34;}], &#34;histogram2dcontour&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;histogram2dcontour&#34;}], &#34;mesh3d&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;mesh3d&#34;}], &#34;parcoords&#34;: [{&#34;line&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;parcoords&#34;}], &#34;pie&#34;: [{&#34;automargin&#34;: true, &#34;type&#34;: &#34;pie&#34;}], &#34;scatter&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatter&#34;}], &#34;scatter3d&#34;: [{&#34;line&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatter3d&#34;}], &#34;scattercarpet&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattercarpet&#34;}], &#34;scattergeo&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattergeo&#34;}], &#34;scattergl&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattergl&#34;}], &#34;scattermapbox&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattermapbox&#34;}], &#34;scatterpolar&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterpolar&#34;}], &#34;scatterpolargl&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterpolargl&#34;}], &#34;scatterternary&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterternary&#34;}], &#34;surface&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;surface&#34;}], &#34;table&#34;: [{&#34;cells&#34;: {&#34;fill&#34;: {&#34;color&#34;: &#34;#EBF0F8&#34;}, &#34;line&#34;: {&#34;color&#34;: &#34;white&#34;}}, &#34;header&#34;: {&#34;fill&#34;: {&#34;color&#34;: &#34;#C8D4E3&#34;}, &#34;line&#34;: {&#34;color&#34;: &#34;white&#34;}}, &#34;type&#34;: &#34;table&#34;}]}, &#34;layout&#34;: {&#34;annotationdefaults&#34;: {&#34;arrowcolor&#34;: &#34;#2a3f5f&#34;, &#34;arrowhead&#34;: 0, &#34;arrowwidth&#34;: 1}, &#34;coloraxis&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;colorscale&#34;: {&#34;diverging&#34;: [[0, &#34;#8e0152&#34;], [0.1, &#34;#c51b7d&#34;], [0.2, &#34;#de77ae&#34;], [0.3, &#34;#f1b6da&#34;], [0.4, &#34;#fde0ef&#34;], [0.5, &#34;#f7f7f7&#34;], [0.6, &#34;#e6f5d0&#34;], [0.7, &#34;#b8e186&#34;], [0.8, &#34;#7fbc41&#34;], [0.9, &#34;#4d9221&#34;], [1, &#34;#276419&#34;]], &#34;sequential&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;sequentialminus&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]]}, &#34;colorway&#34;: [&#34;#636efa&#34;, &#34;#EF553B&#34;, &#34;#00cc96&#34;, &#34;#ab63fa&#34;, &#34;#FFA15A&#34;, &#34;#19d3f3&#34;, &#34;#FF6692&#34;, &#34;#B6E880&#34;, &#34;#FF97FF&#34;, &#34;#FECB52&#34;], &#34;font&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;geo&#34;: {&#34;bgcolor&#34;: &#34;white&#34;, &#34;lakecolor&#34;: &#34;white&#34;, &#34;landcolor&#34;: &#34;#E5ECF6&#34;, &#34;showlakes&#34;: true, &#34;showland&#34;: true, &#34;subunitcolor&#34;: &#34;white&#34;}, &#34;hoverlabel&#34;: {&#34;align&#34;: &#34;left&#34;}, &#34;hovermode&#34;: &#34;closest&#34;, &#34;mapbox&#34;: {&#34;style&#34;: &#34;light&#34;}, &#34;paper_bgcolor&#34;: &#34;white&#34;, &#34;plot_bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;polar&#34;: {&#34;angularaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;radialaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}}, &#34;scene&#34;: {&#34;xaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}, &#34;yaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}, &#34;zaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}}, &#34;shapedefaults&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}}, &#34;ternary&#34;: {&#34;aaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;baxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;caxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}}, &#34;title&#34;: {&#34;x&#34;: 0.05}, &#34;xaxis&#34;: {&#34;automargin&#34;: true, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;, &#34;title&#34;: {&#34;standoff&#34;: 15}, &#34;zerolinecolor&#34;: &#34;white&#34;, &#34;zerolinewidth&#34;: 2}, &#34;yaxis&#34;: {&#34;automargin&#34;: true, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;, &#34;title&#34;: {&#34;standoff&#34;: 15}, &#34;zerolinecolor&#34;: &#34;white&#34;, &#34;zerolinewidth&#34;: 2}}}, &#34;xaxis&#34;: {&#34;anchor&#34;: &#34;y&#34;, &#34;domain&#34;: [0.0, 1.0], &#34;title&#34;: {&#34;text&#34;: &#34;Tags&#34;}}, &#34;yaxis&#34;: {&#34;anchor&#34;: &#34;x&#34;, &#34;domain&#34;: [0.0, 1.0], &#34;title&#34;: {&#34;text&#34;: &#34;Number of infos&#34;}}},
                        {&#34;responsive&#34;: true}
                    ).then(function(){
                            
var gd = document.getElementById(&#39;93a29e39-9a0c-49f1-9585-5d6ba50f38f5&#39;);
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === &#39;none&#39;) {{
            console.log([gd, &#39;removed!&#39;]);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest(&#39;#notebook-container&#39;);
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest(&#39;.output&#39;);
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })
                };
                
            &lt;/script&gt;
        &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;


&lt;p&gt;After we loaded the data, we checked how frequently are the tags being tagged to the articles. Here we only visualized the top-100 tags (you can select area of the figure to zoomin), we can see that there&amp;rsquo;s a big imbalancement of popularity among tags. We can try to mitigate this imbalancement by using different methods like sampling methods and augmentation. But now we&amp;rsquo;ll just pretend we don&amp;rsquo;t know that and leave this aside.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s load the BERT tokenizer and model.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PRETRAINED_BERT_WEIGHTS = download_once_pretrained_transformers(
    &amp;quot;google/bert_uncased_L-4_H-256_A-4&amp;quot;)
tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_BERT_WEIGHTS)
model = AutoModel.from_pretrained(PRETRAINED_BERT_WEIGHTS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we encode all the titles by the BERT-Mini model. We&amp;rsquo;ll use only the 1st output vector from the model as it&amp;rsquo;s used for classification task.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;col_text = &#39;title&#39;
max_length = ds.data[col_text].apply(lambda x: len(nltk.word_tokenize(x))).max()

encoded = ds.data[col_text].apply(
    (lambda x: tokenizer.encode_plus(x, add_special_tokens=True,
                                     pad_to_max_length=True,
                                     return_attention_mask=True,
                                     max_length=max_length,
                                     return_tensors=&#39;pt&#39;)))

input_ids = torch.cat(tuple(encoded.apply(lambda x:x[&#39;input_ids&#39;])))
attention_mask = torch.cat(tuple(encoded.apply(lambda x:x[&#39;attention_mask&#39;])))

features = []
with torch.no_grad():
    last_hidden_states = model(input_ids, attention_mask=attention_mask)
    features = last_hidden_states[0][:, 0, :].numpy()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As the features are changed from Tf-idf transformed to BERT transformed, so we&amp;rsquo;ll re-search for the hyper-parameters for the LinearSVC to use.&lt;/p&gt;

&lt;p&gt;The scorer we used in grid search is f-0.5 score since we want to weight higher precision over recall.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train_features, test_features, train_labels, test_labels = train_test_split(
    features, ds.target, test_size=0.3, random_state=RAND_STATE)
    
clf = OneVsRestClassifier(LinearSVC())

C_OPTIONS = [0.01, 0.1, 0.5, 1, 10]

parameters = {
    &#39;estimator__penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;],
    &#39;estimator__dual&#39;: [True, False],
    &#39;estimator__C&#39;: C_OPTIONS,
}

micro_f05_sco = metrics.make_scorer(
    metrics.fbeta_score, beta=0.5, average=&#39;micro&#39;)

gs_clf = GridSearchCV(clf, parameters,
                      scoring=micro_f05_sco,
                      cv=3, n_jobs=-1)

gs_clf.fit(train_features, train_labels)
print(gs_clf.best_params_)
print(gs_clf.best_score_)

Y_predicted = gs_clf.predict(test_features)

report = metrics.classification_report(
    test_labels, Y_predicted, output_dict=True, zero_division=0)
df_report = pd.DataFrame(report).transpose()
cols_avg = [&#39;micro avg&#39;, &#39;macro avg&#39;, &#39;weighted avg&#39;, &#39;samples avg&#39;]
df_report.loc[cols_avg,]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;estimator__C&#39;: 0.1, &#39;estimator__dual&#39;: True, &#39;estimator__penalty&#39;: &#39;l2&#39;}
0.5793483937857783
&lt;/code&gt;&lt;/pre&gt;




&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;precision&lt;/th&gt;
      &lt;th&gt;recall&lt;/th&gt;
      &lt;th&gt;f1-score&lt;/th&gt;
      &lt;th&gt;support&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;micro avg&lt;/th&gt;
      &lt;td&gt;0.892857&lt;/td&gt;
      &lt;td&gt;0.242326&lt;/td&gt;
      &lt;td&gt;0.381194&lt;/td&gt;
      &lt;td&gt;1238.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;macro avg&lt;/th&gt;
      &lt;td&gt;0.173746&lt;/td&gt;
      &lt;td&gt;0.092542&lt;/td&gt;
      &lt;td&gt;0.111124&lt;/td&gt;
      &lt;td&gt;1238.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;weighted avg&lt;/th&gt;
      &lt;td&gt;0.608618&lt;/td&gt;
      &lt;td&gt;0.242326&lt;/td&gt;
      &lt;td&gt;0.324186&lt;/td&gt;
      &lt;td&gt;1238.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;samples avg&lt;/th&gt;
      &lt;td&gt;0.404088&lt;/td&gt;
      &lt;td&gt;0.274188&lt;/td&gt;
      &lt;td&gt;0.312305&lt;/td&gt;
      &lt;td&gt;1238.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;



&lt;p&gt;Though it&amp;rsquo;s not comparable, the result metrics are no better than the Tf-idf one when we use only the English samples with their titles here. The micro average precision is higher, the other averages of precision are about the same. The recalls got much lower.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s combine the titles and short descriptions to see if there&amp;rsquo;s any improvment.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;col_text = &#39;description&#39;
max_length = ds.data[col_text].apply(lambda x: len(nltk.word_tokenize(x))).max()
encoded = ds.data[col_text].apply(
    (lambda x: tokenizer.encode_plus(x, add_special_tokens=True,
                                     pad_to_max_length=True,
                                     return_attention_mask=True,
                                     max_length=max_length,
                                     return_tensors=&#39;pt&#39;)))

input_ids = torch.cat(tuple(encoded.apply(lambda x:x[&#39;input_ids&#39;])))
attention_mask = torch.cat(tuple(encoded.apply(lambda x:x[&#39;attention_mask&#39;])))

features = []
with torch.no_grad():
    last_hidden_states = model(input_ids, attention_mask=attention_mask)
    features = last_hidden_states[0][:, 0, :].numpy()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;train_features, test_features, train_labels, test_labels = train_test_split(
    features, ds.target, test_size=0.3, random_state=RAND_STATE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;clf = OneVsRestClassifier(LinearSVC())

C_OPTIONS = [0.1, 1]

parameters = {
    &#39;estimator__penalty&#39;: [&#39;l2&#39;],
    &#39;estimator__dual&#39;: [True],
    &#39;estimator__C&#39;: C_OPTIONS,
}

micro_f05_sco = metrics.make_scorer(
    metrics.fbeta_score, beta=0.5, average=&#39;micro&#39;)

gs_clf = GridSearchCV(clf, parameters,
                      scoring=micro_f05_sco,
                      cv=3, n_jobs=-1)

gs_clf.fit(train_features, train_labels)

print(gs_clf.best_params_)
print(gs_clf.best_score_)

Y_predicted = gs_clf.predict(test_features)

classification_report_avg(test_labels, Y_predicted)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;estimator__C&#39;: 1, &#39;estimator__dual&#39;: True, &#39;estimator__penalty&#39;: &#39;l2&#39;}
0.4954311860243222
              precision    recall  f1-score  support
micro avg      0.684015  0.297254  0.414414   1238.0
macro avg      0.178030  0.109793  0.127622   1238.0
weighted avg   0.522266  0.297254  0.362237   1238.0
samples avg    0.401599  0.314649  0.337884   1238.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is no improvement, the precision averages even got a little bit worse. Let&amp;rsquo;s try to explore further.&lt;/p&gt;

&lt;h2 id=&#34;iterative-stratified-multilabel-data-sampling&#34;&gt;Iterative stratified multilabel data sampling&lt;/h2&gt;

&lt;p&gt;It would be a good idea to perform stratified sampling for spliting training and test sets since there&amp;rsquo;s a big imbalancement in the dataset for the labels. The problem is that the size of dataset is very small, which causes it that using normal stratified sampling method would fail since it&amp;rsquo;s likely that some labels may not appear in both training and testing sets. That&amp;rsquo;s why we have to use iterative stratified multilabel sampling. The explanation of this method can refer to &lt;a href=&#34;http://scikit.ml/stratification.html&#34; target=&#34;_blank&#34;&gt;document of scikit-multilearn&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the code below we have wrapped the split method for brevity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;COL_TEXT = &#39;description&#39;

train_features, test_features, train_labels, test_labels = multilearn_iterative_train_test_split(
    ds.data, ds.target, test_size=0.3, cols=ds.data.columns)

batch_size = 128
model_name = &amp;quot;google/bert_uncased_L-4_H-256_A-4&amp;quot;

train_features, test_features = bert_transform(
    train_features, test_features, COL_TEXT, model_name, batch_size)


clf = OneVsRestClassifier(LinearSVC())

C_OPTIONS = [0.1, 1]

parameters = {
    &#39;estimator__penalty&#39;: [&#39;l2&#39;],
    &#39;estimator__dual&#39;: [True],
    &#39;estimator__C&#39;: C_OPTIONS,
}

micro_f05_sco = metrics.make_scorer(
    metrics.fbeta_score, beta=0.5, average=&#39;micro&#39;)

gs_clf = GridSearchCV(clf, parameters,
                      scoring=micro_f05_sco,
                      cv=3, n_jobs=-1)

gs_clf.fit(train_features, train_labels)

print(gs_clf.best_params_)
print(gs_clf.best_score_)

Y_predicted = gs_clf.predict(test_features)

print(classification_report_avg(test_labels, Y_predicted))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;estimator__C&#39;: 0.1, &#39;estimator__dual&#39;: True, &#39;estimator__penalty&#39;: &#39;l2&#39;}
0.3292528001922235
              precision    recall  f1-score  support
micro avg      0.674086  0.356003  0.465934   1191.0
macro avg      0.230836  0.162106  0.181784   1191.0
weighted avg   0.551619  0.356003  0.420731   1191.0
samples avg    0.460420  0.377735  0.392599   1191.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There seems no improvement. But the cross validation F-0.5 score is lower than the testing score. It might be a sign that it&amp;rsquo;s under-fitting.&lt;/p&gt;

&lt;h2 id=&#34;training-set-augmentation&#34;&gt;Training set augmentation&lt;/h2&gt;

&lt;p&gt;As the dataset is quite small, now we&amp;rsquo;ll try to augment the trainig set to see if there&amp;rsquo;s any improvement.&lt;/p&gt;

&lt;p&gt;Here we set the augmentation level to 2, which means the dataset are concatenated by 2 times of the samples. And the added samples&amp;rsquo; content will be randomly chopped out as &lt;sup&gt;9&lt;/sup&gt;&amp;frasl;&lt;sub&gt;10&lt;/sub&gt; of its original content. Of course, both the actions only apply to the training set. The 30% test set is kept aside.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;COL_TEXT = &#39;description&#39;

train_features, test_features, train_labels, test_labels = multilearn_iterative_train_test_split(
    ds.data, ds.target, test_size=0.3, cols=ds.data.columns)

train_features, train_labels = dataset.augmented_samples(
    train_features, train_labels, level=2, crop_ratio=0.1)

batch_size = 128
model_name = &amp;quot;google/bert_uncased_L-4_H-256_A-4&amp;quot;

train_features, test_features = bert_transform(
    train_features, test_features, COL_TEXT, model_name, batch_size)

clf = OneVsRestClassifier(LinearSVC())

C_OPTIONS = [0.1, 1]

parameters = {
    &#39;estimator__penalty&#39;: [&#39;l2&#39;],
    &#39;estimator__dual&#39;: [True],
    &#39;estimator__C&#39;: C_OPTIONS,
}

micro_f05_sco = metrics.make_scorer(
    metrics.fbeta_score, beta=0.5, average=&#39;micro&#39;)

gs_clf = GridSearchCV(clf, parameters,
                      scoring=micro_f05_sco,
                      cv=3, n_jobs=-1)

gs_clf.fit(train_features, train_labels)

print(gs_clf.best_params_)
print(gs_clf.best_score_)

Y_predicted = gs_clf.predict(test_features)

classification_report_avg(test_labels, Y_predicted)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;estimator__C&#39;: 0.1, &#39;estimator__dual&#39;: True, &#39;estimator__penalty&#39;: &#39;l2&#39;}
0.9249583214520737
              precision    recall  f1-score  support
micro avg      0.616296  0.348409  0.445158   1194.0
macro avg      0.224752  0.162945  0.180873   1194.0
weighted avg   0.520024  0.348409  0.406509   1194.0
samples avg    0.442572  0.373784  0.384738   1194.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can see that there&amp;rsquo;s still no improvement. It seems that we should change direction.&lt;/p&gt;

&lt;h2 id=&#34;filter-rare-tags&#34;&gt;Filter rare tags&lt;/h2&gt;

&lt;p&gt;If you remember that the first time we loaded the data we visualized the appearence frequency of the tags. It showed that most of the tags appeared only very few times, over 200 tags appeared only once or twice. This is quite a big problem for the model to classify for these tags.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s try to filter out the least appeared tags. Let&amp;rsquo;s start from a big number of 20, i.e., tags appeared in less than 20 articles will be removed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;col_text = &#39;description&#39;
ds_param = dict(from_batch_cache=&#39;info&#39;, lan=&#39;en&#39;,
                concate_title=True,
                filter_tags_threshold=20)
ds = dataset.ds_info_tags(**ds_param)

c = Counter([tag for tags in ds.target_decoded for tag in tags])

dfc = pd.DataFrame.from_dict(c, orient=&#39;index&#39;, columns=[&#39;count&#39;]).sort_values(by=&#39;count&#39;, ascending=False)[:100]

fig_Y = px.bar(dfc, x=dfc.index, y=&#39;count&#39;,
               text=&#39;count&#39;,
               labels={&#39;count&#39;: &#39;Number of infos&#39;,
                       &#39;x&#39;: &#39;Tags&#39;})
fig_Y.update_traces(texttemplate=&#39;%{text}&#39;)
&lt;/code&gt;&lt;/pre&gt;



&lt;html&gt;
&lt;head&gt;&lt;meta charset=&#34;utf-8&#34; /&gt;&lt;/head&gt;
&lt;body&gt;
    &lt;div&gt;
            &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text/javascript&#34;&gt;if (window.MathJax) {MathJax.Hub.Config({SVG: {font: &#34;STIX-Web&#34;}});}&lt;/script&gt;
                &lt;script type=&#34;text/javascript&#34;&gt;window.PlotlyConfig = {MathJaxConfig: &#39;local&#39;};&lt;/script&gt;
        &lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;    
            &lt;div id=&#34;1c689a44-bec8-4749-bd6f-2a3cc74c5cd9&#34; class=&#34;plotly-graph-div&#34; style=&#34;height:525px; width:100%;&#34;&gt;&lt;/div&gt;
            &lt;script type=&#34;text/javascript&#34;&gt;
                
                    window.PLOTLYENV=window.PLOTLYENV || {};
                    
                if (document.getElementById(&#34;1c689a44-bec8-4749-bd6f-2a3cc74c5cd9&#34;)) {
                    Plotly.newPlot(
                        &#39;1c689a44-bec8-4749-bd6f-2a3cc74c5cd9&#39;,
                        [{&#34;alignmentgroup&#34;: &#34;True&#34;, &#34;hoverlabel&#34;: {&#34;namelength&#34;: 0}, &#34;hovertemplate&#34;: &#34;Tags=%{x}&lt;br&gt;Number of infos=%{text}&#34;, &#34;legendgroup&#34;: &#34;&#34;, &#34;marker&#34;: {&#34;color&#34;: &#34;#636efa&#34;}, &#34;name&#34;: &#34;&#34;, &#34;offsetgroup&#34;: &#34;&#34;, &#34;orientation&#34;: &#34;v&#34;, &#34;showlegend&#34;: false, &#34;text&#34;: [425.0, 272.0, 181.0, 155.0, 129.0, 89.0, 80.0, 77.0, 67.0, 60.0, 53.0, 50.0, 48.0, 47.0, 42.0, 39.0, 39.0, 39.0, 35.0, 35.0, 33.0, 32.0, 32.0, 32.0, 31.0, 31.0, 31.0, 31.0, 30.0, 29.0, 28.0, 27.0, 27.0, 26.0, 26.0, 25.0, 25.0, 25.0, 22.0, 22.0, 21.0], &#34;textposition&#34;: &#34;auto&#34;, &#34;texttemplate&#34;: &#34;%{text}&#34;, &#34;type&#34;: &#34;bar&#34;, &#34;x&#34;: [&#34;python&#34;, &#34;golang&#34;, &#34;web&#34;, &#34;javascript&#34;, &#34;machine-learning&#34;, &#34;microservices&#34;, &#34;deep-learning&#34;, &#34;neural-networks&#34;, &#34;api&#34;, &#34;data-science&#34;, &#34;java&#34;, &#34;node.js&#34;, &#34;testing&#34;, &#34;concurrency&#34;, &#34;vue.js&#34;, &#34;system-architecture&#34;, &#34;react&#34;, &#34;db&#34;, &#34;compiler&#34;, &#34;docker&#34;, &#34;http&#34;, &#34;git&#34;, &#34;kubernetes&#34;, &#34;rust&#34;, &#34;restful&#34;, &#34;data-visualization&#34;, &#34;cpp&#34;, &#34;django&#34;, &#34;nlp&#34;, &#34;oop&#34;, &#34;kafka&#34;, &#34;graphql&#34;, &#34;angular&#34;, &#34;programming&#34;, &#34;linux&#34;, &#34;css&#34;, &#34;frontend&#34;, &#34;security&#34;, &#34;functional-programming&#34;, &#34;interpreter&#34;, &#34;distributed-system&#34;], &#34;xaxis&#34;: &#34;x&#34;, &#34;y&#34;: [425, 272, 181, 155, 129, 89, 80, 77, 67, 60, 53, 50, 48, 47, 42, 39, 39, 39, 35, 35, 33, 32, 32, 32, 31, 31, 31, 31, 30, 29, 28, 27, 27, 26, 26, 25, 25, 25, 22, 22, 21], &#34;yaxis&#34;: &#34;y&#34;}],
                        {&#34;barmode&#34;: &#34;relative&#34;, &#34;legend&#34;: {&#34;tracegroupgap&#34;: 0}, &#34;margin&#34;: {&#34;t&#34;: 60}, &#34;template&#34;: {&#34;data&#34;: {&#34;bar&#34;: [{&#34;error_x&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;error_y&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;marker&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#E5ECF6&#34;, &#34;width&#34;: 0.5}}, &#34;type&#34;: &#34;bar&#34;}], &#34;barpolar&#34;: [{&#34;marker&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#E5ECF6&#34;, &#34;width&#34;: 0.5}}, &#34;type&#34;: &#34;barpolar&#34;}], &#34;carpet&#34;: [{&#34;aaxis&#34;: {&#34;endlinecolor&#34;: &#34;#2a3f5f&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;minorgridcolor&#34;: &#34;white&#34;, &#34;startlinecolor&#34;: &#34;#2a3f5f&#34;}, &#34;baxis&#34;: {&#34;endlinecolor&#34;: &#34;#2a3f5f&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;minorgridcolor&#34;: &#34;white&#34;, &#34;startlinecolor&#34;: &#34;#2a3f5f&#34;}, &#34;type&#34;: &#34;carpet&#34;}], &#34;choropleth&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;choropleth&#34;}], &#34;contour&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;contour&#34;}], &#34;contourcarpet&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;contourcarpet&#34;}], &#34;heatmap&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;heatmap&#34;}], &#34;heatmapgl&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;heatmapgl&#34;}], &#34;histogram&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;histogram&#34;}], &#34;histogram2d&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;histogram2d&#34;}], &#34;histogram2dcontour&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;histogram2dcontour&#34;}], &#34;mesh3d&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;type&#34;: &#34;mesh3d&#34;}], &#34;parcoords&#34;: [{&#34;line&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;parcoords&#34;}], &#34;pie&#34;: [{&#34;automargin&#34;: true, &#34;type&#34;: &#34;pie&#34;}], &#34;scatter&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatter&#34;}], &#34;scatter3d&#34;: [{&#34;line&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatter3d&#34;}], &#34;scattercarpet&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattercarpet&#34;}], &#34;scattergeo&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattergeo&#34;}], &#34;scattergl&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattergl&#34;}], &#34;scattermapbox&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scattermapbox&#34;}], &#34;scatterpolar&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterpolar&#34;}], &#34;scatterpolargl&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterpolargl&#34;}], &#34;scatterternary&#34;: [{&#34;marker&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;type&#34;: &#34;scatterternary&#34;}], &#34;surface&#34;: [{&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}, &#34;colorscale&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;type&#34;: &#34;surface&#34;}], &#34;table&#34;: [{&#34;cells&#34;: {&#34;fill&#34;: {&#34;color&#34;: &#34;#EBF0F8&#34;}, &#34;line&#34;: {&#34;color&#34;: &#34;white&#34;}}, &#34;header&#34;: {&#34;fill&#34;: {&#34;color&#34;: &#34;#C8D4E3&#34;}, &#34;line&#34;: {&#34;color&#34;: &#34;white&#34;}}, &#34;type&#34;: &#34;table&#34;}]}, &#34;layout&#34;: {&#34;annotationdefaults&#34;: {&#34;arrowcolor&#34;: &#34;#2a3f5f&#34;, &#34;arrowhead&#34;: 0, &#34;arrowwidth&#34;: 1}, &#34;coloraxis&#34;: {&#34;colorbar&#34;: {&#34;outlinewidth&#34;: 0, &#34;ticks&#34;: &#34;&#34;}}, &#34;colorscale&#34;: {&#34;diverging&#34;: [[0, &#34;#8e0152&#34;], [0.1, &#34;#c51b7d&#34;], [0.2, &#34;#de77ae&#34;], [0.3, &#34;#f1b6da&#34;], [0.4, &#34;#fde0ef&#34;], [0.5, &#34;#f7f7f7&#34;], [0.6, &#34;#e6f5d0&#34;], [0.7, &#34;#b8e186&#34;], [0.8, &#34;#7fbc41&#34;], [0.9, &#34;#4d9221&#34;], [1, &#34;#276419&#34;]], &#34;sequential&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]], &#34;sequentialminus&#34;: [[0.0, &#34;#0d0887&#34;], [0.1111111111111111, &#34;#46039f&#34;], [0.2222222222222222, &#34;#7201a8&#34;], [0.3333333333333333, &#34;#9c179e&#34;], [0.4444444444444444, &#34;#bd3786&#34;], [0.5555555555555556, &#34;#d8576b&#34;], [0.6666666666666666, &#34;#ed7953&#34;], [0.7777777777777778, &#34;#fb9f3a&#34;], [0.8888888888888888, &#34;#fdca26&#34;], [1.0, &#34;#f0f921&#34;]]}, &#34;colorway&#34;: [&#34;#636efa&#34;, &#34;#EF553B&#34;, &#34;#00cc96&#34;, &#34;#ab63fa&#34;, &#34;#FFA15A&#34;, &#34;#19d3f3&#34;, &#34;#FF6692&#34;, &#34;#B6E880&#34;, &#34;#FF97FF&#34;, &#34;#FECB52&#34;], &#34;font&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}, &#34;geo&#34;: {&#34;bgcolor&#34;: &#34;white&#34;, &#34;lakecolor&#34;: &#34;white&#34;, &#34;landcolor&#34;: &#34;#E5ECF6&#34;, &#34;showlakes&#34;: true, &#34;showland&#34;: true, &#34;subunitcolor&#34;: &#34;white&#34;}, &#34;hoverlabel&#34;: {&#34;align&#34;: &#34;left&#34;}, &#34;hovermode&#34;: &#34;closest&#34;, &#34;mapbox&#34;: {&#34;style&#34;: &#34;light&#34;}, &#34;paper_bgcolor&#34;: &#34;white&#34;, &#34;plot_bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;polar&#34;: {&#34;angularaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;radialaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}}, &#34;scene&#34;: {&#34;xaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}, &#34;yaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}, &#34;zaxis&#34;: {&#34;backgroundcolor&#34;: &#34;#E5ECF6&#34;, &#34;gridcolor&#34;: &#34;white&#34;, &#34;gridwidth&#34;: 2, &#34;linecolor&#34;: &#34;white&#34;, &#34;showbackground&#34;: true, &#34;ticks&#34;: &#34;&#34;, &#34;zerolinecolor&#34;: &#34;white&#34;}}, &#34;shapedefaults&#34;: {&#34;line&#34;: {&#34;color&#34;: &#34;#2a3f5f&#34;}}, &#34;ternary&#34;: {&#34;aaxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;baxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}, &#34;bgcolor&#34;: &#34;#E5ECF6&#34;, &#34;caxis&#34;: {&#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;}}, &#34;title&#34;: {&#34;x&#34;: 0.05}, &#34;xaxis&#34;: {&#34;automargin&#34;: true, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;, &#34;title&#34;: {&#34;standoff&#34;: 15}, &#34;zerolinecolor&#34;: &#34;white&#34;, &#34;zerolinewidth&#34;: 2}, &#34;yaxis&#34;: {&#34;automargin&#34;: true, &#34;gridcolor&#34;: &#34;white&#34;, &#34;linecolor&#34;: &#34;white&#34;, &#34;ticks&#34;: &#34;&#34;, &#34;title&#34;: {&#34;standoff&#34;: 15}, &#34;zerolinecolor&#34;: &#34;white&#34;, &#34;zerolinewidth&#34;: 2}}}, &#34;xaxis&#34;: {&#34;anchor&#34;: &#34;y&#34;, &#34;domain&#34;: [0.0, 1.0], &#34;title&#34;: {&#34;text&#34;: &#34;Tags&#34;}}, &#34;yaxis&#34;: {&#34;anchor&#34;: &#34;x&#34;, &#34;domain&#34;: [0.0, 1.0], &#34;title&#34;: {&#34;text&#34;: &#34;Number of infos&#34;}}},
                        {&#34;responsive&#34;: true}
                    ).then(function(){
                            
var gd = document.getElementById(&#39;1c689a44-bec8-4749-bd6f-2a3cc74c5cd9&#39;);
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === &#39;none&#39;) {{
            console.log([gd, &#39;removed!&#39;]);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest(&#39;#notebook-container&#39;);
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest(&#39;.output&#39;);
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })
                };
                
            &lt;/script&gt;
        &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;


&lt;pre&gt;&lt;code&gt;test_size = 0.3
train_features, test_features, train_labels, test_labels = multilearn_iterative_train_test_split(
    ds.data, ds.target, test_size=test_size, cols=ds.data.columns)

train_features, train_labels = dataset.augmented_samples(
    train_features, train_labels, level=2, crop_ratio=0.1)

batch_size = 128
model_name = &amp;quot;google/bert_uncased_L-4_H-256_A-4&amp;quot;

train_features, test_features = bert_transform(
    train_features, test_features, col_text, model_name, batch_size)

clf = OneVsRestClassifier(LinearSVC())

C_OPTIONS = [0.1, 1]

parameters = {
    &#39;estimator__penalty&#39;: [&#39;l2&#39;],
    &#39;estimator__dual&#39;: [True],
    &#39;estimator__C&#39;: C_OPTIONS,
}

micro_f05_sco = metrics.make_scorer(
    metrics.fbeta_score, beta=0.5, average=&#39;micro&#39;)

gs_clf = GridSearchCV(clf, parameters,
                      scoring=micro_f05_sco,
                      cv=3, n_jobs=-1)

gs_clf.fit(train_features, train_labels)
print(f&#39;Best params in CV: {gs_clf.best_params_}&#39;)
print(f&#39;Best score in CV: {gs_clf.best_score_}&#39;)

Y_predicted = gs_clf.predict(test_features)

classification_report_avg(test_labels, Y_predicted)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Best params in CV: {&#39;estimator__C&#39;: 0.1, &#39;estimator__dual&#39;: True, &#39;estimator__penalty&#39;: &#39;l2&#39;}
Best score in CV: 0.8943719982878996
              precision    recall  f1-score  support
micro avg      0.593583  0.435294  0.502262    765.0
macro avg      0.523965  0.361293  0.416650    765.0
weighted avg   0.586632  0.435294  0.490803    765.0
samples avg    0.458254  0.472063  0.444127    765.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The filtering of tags made the averages of recall higher, but made the precision lower. The macro average goes up as there&amp;rsquo;re much fewer tags.&lt;/p&gt;

&lt;h2 id=&#34;fine-tuning-bert-model&#34;&gt;Fine-tuning BERT model&lt;/h2&gt;

&lt;p&gt;The next step is to see if we can make some progress by fine-tuning the BERT-Mini model. As for a comparable result, the fine-tuning training will be using the same dataset that filtered of tags appear at least in 20 infos. The final classifier model will also be the same of SVM with Linear kernel feeded by the embeddings from the fine-tuned BERT-Mini.&lt;/p&gt;

&lt;p&gt;The processing of fine-tuning refers much to &lt;a href=&#34;https://mccormickml.com/2019/07/22/BERT-fine-tuning/&#34; target=&#34;_blank&#34;&gt;Chris McCormick&amp;rsquo;s post&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;col_text = &#39;description&#39;
ds_param = dict(from_batch_cache=&#39;info&#39;, lan=&#39;en&#39;,
                concate_title=True,
                filter_tags_threshold=20)
ds = dataset.ds_info_tags(**ds_param)

test_size = 0.3
train_features, test_features, train_labels, test_labels = multilearn_iterative_train_test_split(
    ds.data, ds.target, test_size=test_size, cols=ds.data.columns)

train_features, train_labels = dataset.augmented_samples(
    train_features, train_labels, level=2, crop_ratio=0.1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;BertForSequenceMultiLabelClassification&lt;/code&gt; class defined below is basically a copy of the &lt;code&gt;BertForSequenceClassification&lt;/code&gt; class in huggingface&amp;rsquo;s &lt;code&gt;Transformers&lt;/code&gt;, only with a small change of adding &lt;code&gt;sigmoid&lt;/code&gt; the logits from classification and adding &lt;code&gt;labels = torch.max(labels, 1)[1]&lt;/code&gt; in &lt;code&gt;forward&lt;/code&gt; for supporting multilabel.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class BertForSequenceMultiLabelClassification(BertPreTrainedModel):
    def __init__(self, config):
        super(BertForSequenceMultiLabelClassification, self).__init__(config)
        self.num_labels = config.num_labels

        self.bert = BertModel(config)
        self.dropout = nn.Dropout(config.hidden_dropout_prob)
        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)

        self.init_weights()

    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,
                position_ids=None, head_mask=None, inputs_embeds=None, labels=None):

        outputs = self.bert(input_ids,
                            attention_mask=attention_mask,
                            token_type_ids=token_type_ids,
                            position_ids=position_ids,
                            head_mask=head_mask,
                            inputs_embeds=inputs_embeds)

        pooled_output = outputs[1]

        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        logtis = torch.sigmoid(logits)
        # add hidden states and attention if they are here
        outputs = (logits,) + outputs[2:]

        if labels is not None:
            if self.num_labels == 1:
                #  We are doing regression
                loss_fct = nn.MSELoss()
                loss = loss_fct(logits.view(-1), labels.view(-1))
            else:
                loss_fct = nn.CrossEntropyLoss()

                labels = torch.max(labels, 1)[1]

                loss = loss_fct(
                    logits.view(-1, self.num_labels), labels.view(-1))
            outputs = (loss,) + outputs

        return outputs  # (loss), logits, (hidden_states), (attentions)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DEVICE = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;
n_classes = train_labels.shape[1]
batch_size: int = 16
epochs: int = 4

model_name = download_once_pretrained_transformers(
    &amp;quot;google/bert_uncased_L-4_H-256_A-4&amp;quot;)

model = BertForSequenceMultiLabelClassification.from_pretrained(
    model_name,
    num_labels=n_classes,
    output_attentions=False,  
    output_hidden_states=False,
)

model.to(DEVICE)

# Prepare optimizer and schedule (linear warmup and decay)
no_decay = [&amp;quot;bias&amp;quot;, &amp;quot;LayerNorm.weight&amp;quot;]
optimizer_grouped_parameters = [
    {&amp;quot;params&amp;quot;: [p for n, p in model.named_parameters() if not any(
        nd in n for nd in no_decay)], &amp;quot;weight_decay&amp;quot;: 0.1,
     },
    {&amp;quot;params&amp;quot;: [p for n, p in model.named_parameters() if any(
        nd in n for nd in no_decay)], &amp;quot;weight_decay&amp;quot;: 0.0},
]

optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5,  eps=1e-8  )

tokenizer, model_notuse = get_tokenizer_model(model_name)

input_ids, attention_mask = bert_tokenize(
    tokenizer, train_features, col_text=col_text)
input_ids_test, attention_mask_test = bert_tokenize(
    tokenizer, test_features, col_text=col_text)

train_set = torch.utils.data.TensorDataset(
    input_ids, attention_mask, torch.Tensor(train_labels))
test_set = torch.utils.data.TensorDataset(
    input_ids_test, attention_mask_test, torch.Tensor(test_labels))

train_loader = torch.utils.data.DataLoader(
    train_set, batch_size=batch_size, sampler=RandomSampler(train_set))
test_loader = torch.utils.data.DataLoader(
    test_set, sampler=SequentialSampler(test_set), batch_size=batch_size)


total_steps = len(train_loader) * epochs

scheduler = get_linear_schedule_with_warmup(optimizer,
                                            num_warmup_steps=0,  # Default value in run_glue.py
                                            num_training_steps=total_steps)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;training_stats = []


def best_prec_score(true_labels, predictions):
    fbeta = 0
    thr_bst = 0
    for thr in range(0, 6):
        Y_predicted = (predictions &amp;gt; (thr * 0.1))

        f = metrics.average_precision_score(
            true_labels, Y_predicted, average=&#39;micro&#39;)
        if f &amp;gt; fbeta:
            fbeta = f
            thr_bst = thr * 0.1

    return fbeta, thr


def train():
    model.train()

    total_train_loss = 0

    for step, (input_ids, masks, labels) in enumerate(train_loader):
        input_ids, masks, labels = input_ids.to(
            DEVICE), masks.to(DEVICE), labels.to(DEVICE)

        model.zero_grad()
        loss, logits = model(input_ids, token_type_ids=None,
                             attention_mask=masks, labels=labels)

        total_train_loss += loss.item()
        loss.backward()

        # Clip the norm of the gradients to 1.0.
        # This is to help prevent the &amp;quot;exploding gradients&amp;quot; problem.
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

        optimizer.step()
        scheduler.step()

    avg_train_loss = total_train_loss / len(train_loader)
    print(&amp;quot;Train loss: {0:.2f}&amp;quot;.format(avg_train_loss))


def val():
    model.eval()

    val_loss = 0

    y_pred, y_true = [], []
    # Evaluate data for one epoch
    for (input_ids, masks, labels) in test_loader:

        input_ids, masks, labels = input_ids.to(
            DEVICE), masks.to(DEVICE), labels.to(DEVICE)

        with torch.no_grad():
            (loss, logits) = model(input_ids,
                                   token_type_ids=None,
                                   attention_mask=masks,
                                   labels=labels)

        val_loss += loss.item()

        logits = logits.detach().cpu().numpy()
        label_ids = labels.to(&#39;cpu&#39;).numpy()

        y_pred += logits.tolist()
        y_true += label_ids.tolist()

    bes_val_prec, bes_val_prec_thr = best_prec_score(
        np.array(y_true), np.array(y_pred))
    y_predicted = (np.array(y_pred) &amp;gt; 0.5)

    avg_val_loss = val_loss / len(test_loader)

    print(&amp;quot;Val loss: {0:.2f}&amp;quot;.format(avg_val_loss))
    print(&amp;quot;best prec: {0:.4f}, thr: {1}&amp;quot;.format(
        bes_val_prec, bes_val_prec_thr))
    print(classification_report_avg(y_true, y_predicted))

for ep in range(epochs):
    print(f&#39;-------------- Epoch: {ep+1}/{epochs} --------------&#39;)
    train()
    val()

print(&#39;-------------- Completed --------------&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-------------- Epoch: 1/4 --------------
Train loss: 2.94
Val loss: 2.35
best prec: 0.1540, thr: 5
              precision    recall  f1-score  support
micro avg      0.233079  0.599476  0.335654    764.0
macro avg      0.185025  0.294674  0.196651    764.0
weighted avg   0.225475  0.599476  0.292065    764.0
samples avg    0.252645  0.634959  0.342227    764.0
-------------- Epoch: 2/4 --------------
Train loss: 2.14
Val loss: 1.92
best prec: 0.1848, thr: 5
              precision    recall  f1-score  support
micro avg      0.255676  0.678010  0.371326    764.0
macro avg      0.381630  0.448064  0.303961    764.0
weighted avg   0.328057  0.678010  0.355185    764.0
samples avg    0.273901  0.735660  0.379705    764.0
-------------- Epoch: 3/4 --------------
Train loss: 1.78
Val loss: 1.74
best prec: 0.1881, thr: 5
              precision    recall  f1-score  support
micro avg      0.248974  0.714660  0.369293    764.0
macro avg      0.272232  0.524172  0.306814    764.0
weighted avg   0.275572  0.714660  0.364002    764.0
samples avg    0.273428  0.776291  0.383235    764.0
-------------- Epoch: 4/4 --------------
Train loss: 1.61
Val loss: 1.68
best prec: 0.1882, thr: 5
              precision    recall  f1-score  support
micro avg      0.244105  0.731675  0.366077    764.0
macro avg      0.288398  0.552318  0.310797    764.0
weighted avg   0.294521  0.731675  0.369942    764.0
samples avg    0.267708  0.795730  0.381341    764.0
-------------- Completed --------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save the fine-tuned model for later encoding.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from transformers import WEIGHTS_NAME, CONFIG_NAME, BertTokenizer

output_dir = &amp;quot;./data/models/bert_finetuned_tagthr_20/&amp;quot;

if not os.path.exists(output_dir):
    os.makedirs(output_dir)
# Step 1: Save a model, configuration and vocabulary that you have fine-tuned

# If we have a distributed model, save only the encapsulated model
# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)
model_to_save = model.module if hasattr(model, &#39;module&#39;) else model

# If we save using the predefined names, we can load using `from_pretrained`
output_model_file = os.path.join(output_dir, WEIGHTS_NAME)
output_config_file = os.path.join(output_dir, CONFIG_NAME)

torch.save(model_to_save.state_dict(), output_model_file)
model_to_save.config.to_json_file(output_config_file)
tokenizer.save_vocabulary(output_dir)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(&#39;./data/models/bert_finetuned_tagthr_20/vocab.txt&#39;,)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s use the fine-tuned model to get the embeddings for the same SVM classification.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;col_text = &#39;description&#39;
ds_param = dict(from_batch_cache=&#39;info&#39;, lan=&#39;en&#39;,
                concate_title=True,
                filter_tags_threshold=20)
ds = dataset.ds_info_tags(**ds_param)

test_size = 0.3
train_features, test_features, train_labels, test_labels = multilearn_iterative_train_test_split(
    ds.data, ds.target, test_size=test_size, cols=ds.data.columns)

train_features, train_labels = dataset.augmented_samples(
    train_features, train_labels, level=2, crop_ratio=0.1)

batch_size = 128
model_name = output_dir

train_features, test_features = bert_transform(
    train_features, test_features, col_text, model_name, batch_size)


clf = OneVsRestClassifier(LinearSVC())

C_OPTIONS = [0.1, 1, 10]

parameters = {
    &#39;estimator__penalty&#39;: [&#39;l2&#39;],
    &#39;estimator__dual&#39;: [True],
    &#39;estimator__C&#39;: C_OPTIONS,
}

micro_f05_sco = metrics.make_scorer(
    metrics.fbeta_score, beta=0.5, average=&#39;micro&#39;)

gs_clf = GridSearchCV(clf, parameters,
                      scoring=micro_f05_sco,
                      cv=3, n_jobs=-1)

gs_clf.fit(train_features, train_labels)

print(gs_clf.best_params_)
print(gs_clf.best_score_)

Y_predicted = gs_clf.predict(test_features)

report = metrics.classification_report(
    test_labels, Y_predicted, output_dict=True)
df_report = pd.DataFrame(report).transpose()
cols_avg = [&#39;micro avg&#39;, &#39;macro avg&#39;, &#39;weighted avg&#39;, &#39;samples avg&#39;]
df_report.loc[cols_avg]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;estimator__C&#39;: 0.1, &#39;estimator__dual&#39;: True, &#39;estimator__penalty&#39;: &#39;l2&#39;}
0.945576388765271
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;precision&lt;/th&gt;
      &lt;th&gt;recall&lt;/th&gt;
      &lt;th&gt;f1-score&lt;/th&gt;
      &lt;th&gt;support&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;micro avg&lt;/th&gt;
      &lt;td&gt;0.793605&lt;/td&gt;
      &lt;td&gt;0.714660&lt;/td&gt;
      &lt;td&gt;0.752066&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;macro avg&lt;/th&gt;
      &lt;td&gt;0.757259&lt;/td&gt;
      &lt;td&gt;0.642333&lt;/td&gt;
      &lt;td&gt;0.671768&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;weighted avg&lt;/th&gt;
      &lt;td&gt;0.782557&lt;/td&gt;
      &lt;td&gt;0.714660&lt;/td&gt;
      &lt;td&gt;0.732094&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;samples avg&lt;/th&gt;
      &lt;td&gt;0.798664&lt;/td&gt;
      &lt;td&gt;0.762087&lt;/td&gt;
      &lt;td&gt;0.754289&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;There&amp;rsquo;s quite a big improvement to both precision and recall after fine-tuning. This result makes the model quite usable.&lt;/p&gt;

&lt;h1 id=&#34;comeback-test-with-tf-idf&#34;&gt;Comeback test with tf-idf&lt;/h1&gt;

&lt;p&gt;Comparing to the early post that the model uses tf-idf to transform the text, we&amp;rsquo;ve made some changes to the dataset loading, spliting and augmentation. I&amp;rsquo;m curious to see if these changes would improve the performance when using tf-idf other than BERT.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with samples only in English still.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;col_text = &#39;description&#39;

ds_param = dict(from_batch_cache=&#39;info&#39;, lan=&#39;en&#39;,
                concate_title=True,
                filter_tags_threshold=20)
ds = dataset.ds_info_tags(**ds_param)

train_features, test_features, train_labels, test_labels = multilearn_iterative_train_test_split(
    ds.data, ds.target, test_size=0.3, cols=ds.data.columns)

train_features, train_labels = dataset.augmented_samples(
    train_features, train_labels, level=4, crop_ratio=0.2)

clf = Pipeline([
    (&#39;vect&#39;, TfidfVectorizer(use_idf=True, max_df=0.8)),
    (&#39;clf&#39;, OneVsRestClassifier(LinearSVC(penalty=&#39;l2&#39;, dual=True))),
])

C_OPTIONS = [0.1, 1, 10]

parameters = {
    &#39;vect__ngram_range&#39;: [(1, 4)],
    &#39;clf__estimator__C&#39;: C_OPTIONS,
}
gs_clf = GridSearchCV(clf, parameters, cv=3, n_jobs=-1)
gs_clf.fit(train_features[col_text], train_labels)

print(gs_clf.best_params_)
print(gs_clf.best_score_)

Y_predicted = gs_clf.predict(test_features[col_text])

classification_report_avg(test_labels, Y_predicted)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;clf__estimator__C&#39;: 10, &#39;vect__ngram_range&#39;: (1, 4)}
0.9986905637969986
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;precision&lt;/th&gt;
      &lt;th&gt;recall&lt;/th&gt;
      &lt;th&gt;f1-score&lt;/th&gt;
      &lt;th&gt;support&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;micro avg&lt;/th&gt;
      &lt;td&gt;0.955782&lt;/td&gt;
      &lt;td&gt;0.367801&lt;/td&gt;
      &lt;td&gt;0.531191&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;macro avg&lt;/th&gt;
      &lt;td&gt;0.740347&lt;/td&gt;
      &lt;td&gt;0.250587&lt;/td&gt;
      &lt;td&gt;0.353632&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;weighted avg&lt;/th&gt;
      &lt;td&gt;0.847419&lt;/td&gt;
      &lt;td&gt;0.367801&lt;/td&gt;
      &lt;td&gt;0.487887&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;samples avg&lt;/th&gt;
      &lt;td&gt;0.452608&lt;/td&gt;
      &lt;td&gt;0.396469&lt;/td&gt;
      &lt;td&gt;0.412913&lt;/td&gt;
      &lt;td&gt;764.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now let&amp;rsquo;s try samples in both English and Chinese.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;col_text = &#39;description&#39;

ds_param = dict(from_batch_cache=&#39;info&#39;, lan=None,
                concate_title=True,
                filter_tags_threshold=20)
ds = dataset.ds_info_tags(**ds_param)

train_features, test_features, train_labels, test_labels = multilearn_iterative_train_test_split(
    ds.data, ds.target, test_size=0.3, cols=ds.data.columns)

train_features, train_labels = dataset.augmented_samples(
    train_features, train_labels, level=4, crop_ratio=0.2)

clf = Pipeline([
    (&#39;vect&#39;, TfidfVectorizer(use_idf=True, max_df=0.8)),
    (&#39;clf&#39;, OneVsRestClassifier(LinearSVC(penalty=&#39;l2&#39;, dual=True))),
])

C_OPTIONS = [0.1, 1, 10]

parameters = {
    &#39;vect__ngram_range&#39;: [(1, 4)],
    &#39;clf__estimator__C&#39;: C_OPTIONS,
}
gs_clf = GridSearchCV(clf, parameters, cv=3, n_jobs=-1)
gs_clf.fit(train_features[col_text], train_labels)

print(gs_clf.best_params_)
print(gs_clf.best_score_)

Y_predicted = gs_clf.predict(test_features[col_text])

classification_report_avg(test_labels, Y_predicted)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;clf__estimator__C&#39;: 10, &#39;vect__ngram_range&#39;: (1, 4)}
0.9962557077625571
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;precision&lt;/th&gt;
      &lt;th&gt;recall&lt;/th&gt;
      &lt;th&gt;f1-score&lt;/th&gt;
      &lt;th&gt;support&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;micro avg&lt;/th&gt;
      &lt;td&gt;0.884273&lt;/td&gt;
      &lt;td&gt;0.417952&lt;/td&gt;
      &lt;td&gt;0.567619&lt;/td&gt;
      &lt;td&gt;1426.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;macro avg&lt;/th&gt;
      &lt;td&gt;0.804614&lt;/td&gt;
      &lt;td&gt;0.311396&lt;/td&gt;
      &lt;td&gt;0.423867&lt;/td&gt;
      &lt;td&gt;1426.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;weighted avg&lt;/th&gt;
      &lt;td&gt;0.849494&lt;/td&gt;
      &lt;td&gt;0.417952&lt;/td&gt;
      &lt;td&gt;0.532041&lt;/td&gt;
      &lt;td&gt;1426.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;samples avg&lt;/th&gt;
      &lt;td&gt;0.487522&lt;/td&gt;
      &lt;td&gt;0.433421&lt;/td&gt;
      &lt;td&gt;0.446447&lt;/td&gt;
      &lt;td&gt;1426.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We can see that, for both the models, the micro average precision is quite high and the recalls are still low. However, the macro averages are much better since we filtered out minority tags. The model trained on samples with both languages has a lower precisions but higher recalls.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Topic Tag Predictor</title>
      <link>https://pcx.linkedinfo.co/project/topic-tag-predictor/</link>
      <pubDate>Sat, 04 Jan 2020 19:22:26 +0100</pubDate>
      <guid>https://pcx.linkedinfo.co/project/topic-tag-predictor/</guid>
      <description>&lt;p&gt;A topic tag prediction service for technical articles. The model uses a pre-trained BERT and fine-tuned on the dataset of LinkedInfo.co.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-label classification to predict topic tags of technical articles from LinkedInfo.co</title>
      <link>https://pcx.linkedinfo.co/post/text-tag-prediction/</link>
      <pubDate>Wed, 11 Sep 2019 13:36:43 +0200</pubDate>
      <guid>https://pcx.linkedinfo.co/post/text-tag-prediction/</guid>
      <description>
&lt;p&gt;
This code snippet is to predict topic tags based on the text of an article. Each article could have 1 or more tags (usually have at least 1 tag), and the tags are not mutually exclusive. So this is a multi-label classification problem. It&amp;#39;s different from multi-class classification, the classes in multi-class classification are mutually exclusive, i.e., each item belongs to 1 and only 1 class.
&lt;/p&gt;
&lt;p&gt;
In this snippet, we will use &lt;code class=&#34;verbatim&#34;&gt;OneVsRestClassifier&lt;/code&gt; (the One-Vs-the-Rest) in scikit-learn to process the multi-label classification. The article data will be retrieved from &lt;a href=&#34;https://linkedinfo.co&#34;&gt;LinkedInfo.co&lt;/a&gt; via Web API. The methods in this snippet should give credits to &lt;a href=&#34;https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html&#34;&gt;Working With Text Data - scikit-learn&lt;/a&gt; and &lt;a href=&#34;https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff&#34;&gt;this post&lt;/a&gt;.
&lt;/p&gt;
    
  &lt;h2&gt;Table of Contents&lt;/h2&gt;
  HAHAHUGOSHORTCODE-TOC0-HBHB
&lt;h2 id=&#34;preprocessing-data-and-explore-the-method&#34;&gt;
Preprocessing data and explore the method
&lt;/h2&gt;
&lt;p&gt;
&lt;code class=&#34;verbatim&#34;&gt;dataset.df_tags&lt;/code&gt; fetches the data set from &lt;a href=&#34;https://linkedinfo.co&#34;&gt;LinkedInfo.co&lt;/a&gt;. It calls Web API of LinkedInfo.co to retrieve the article list, and then download and extract the full text of each article based on an article&amp;#39;s url. The tags of each article are encoded using &lt;code class=&#34;verbatim&#34;&gt;MultiLabelBinarizer&lt;/code&gt; in scikit-learn. The implementation of the code could be found in &lt;a href=&#34;https://github.com/ddxgz/linkedinfo-ml-models/blob/master/dataset.py&#34;&gt;dataset.py&lt;/a&gt;. We&amp;#39;ve set the parameter of &lt;code class=&#34;verbatim&#34;&gt;content_length_threshold&lt;/code&gt; to 100 to screen out the articles with less than 100 for the description or full text.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; dataset

ds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;df_tags(content_length_threshold&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
The dataset contains 3353 articles by the time retrieved the data. The
dataset re returned as an object with the following attribute:
&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
ds.data: pandas.DataFrame with cols of title, description, fulltext
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
ds.target: encoding of tagsID
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
ds.target_names: tagsID
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
ds.target_decoded: the list of lists contains tagsID for each info
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&#34;align-right&#34;&gt;&lt;/td&gt;
&lt;td&gt;description&lt;/td&gt;
&lt;td&gt;fulltext&lt;/td&gt;
&lt;td&gt;title&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;align-right&#34;&gt;0&lt;/td&gt;
&lt;td&gt;Both HTTP 1.x and HTTP/2 rely on lower level c…&lt;/td&gt;
&lt;td&gt;[Stressgrid](&lt;em&gt;)\n\n__\n\n[](&lt;/em&gt; &amp;#34;home&amp;#34;)\n\n * […&lt;/td&gt;
&lt;td&gt;Achieving 100k connections per second with Elixir&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;align-right&#34;&gt;1&lt;/td&gt;
&lt;td&gt;At Phusion we run a simple multithreaded HTTP …&lt;/td&gt;
&lt;td&gt;[![Hongli Lai](&lt;em&gt;images/avatar-b64f1ad5.png)](&lt;/em&gt;…&lt;/td&gt;
&lt;td&gt;What causes Ruby memory bloat?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;align-right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Have you ever wanted to contribute to a projec…&lt;/td&gt;
&lt;td&gt;[ ![Real Python](/static/real-python-logo.ab1a…&lt;/td&gt;
&lt;td&gt;Managing Multiple Python Versions With pyenv&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;align-right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;安卓在版本Pie中第一次引入了ART优化配置文件，这个新特性利用发送到Play Cloud的…&lt;/td&gt;
&lt;td&gt;安卓在版本Pie中第一次引入了[ART优化配置文件](&lt;a href=&#34;https://youtu.be/Yi...&#34;&gt;https://youtu.be/Yi...&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;ART云配置文件，提高安卓应用的性能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;align-right&#34;&gt;4&lt;/td&gt;
&lt;td&gt;I work at Red Hat on GCC, the GNU Compiler Col…&lt;/td&gt;
&lt;td&gt;[ ![Red Hat\nLogo](&lt;a href=&#34;https://developers.redhat.c...&#34;&gt;https://developers.redhat.c...&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Usability improvements in GCC 9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
       [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
       [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
       [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
       [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target_names[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
array([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;academia&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;access-control&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;activemq&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;aes&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;agile&amp;#39;&lt;/span&gt;],
      dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;object)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target_decoded[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;concurrency&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elixir&amp;#39;&lt;/span&gt;],
 [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;],
 [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualenv&amp;#39;&lt;/span&gt;],
 [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;android&amp;#39;&lt;/span&gt;],
 [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gcc&amp;#39;&lt;/span&gt;]]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
The following snippet is the actual process of getting the above
dataset, by reading from file.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; json
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.preprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MultiLabelBinarizer

infos_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;data/infos/infos_0_3353_fulltext.json&amp;#39;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(infos_file, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; f:
    infos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(f)

content_length_threshold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

data_lst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
tags_lst &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; info &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; infos[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;]:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fulltext&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; content_length_threshold:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;description&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; content_length_threshold:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
    data_lst&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;: info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;],
                     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;description&amp;#39;&lt;/span&gt;: info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;description&amp;#39;&lt;/span&gt;],
                     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fulltext&amp;#39;&lt;/span&gt;: info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fulltext&amp;#39;&lt;/span&gt;]})
    tags_lst&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([tag[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tagID&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; tag &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; info[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tags&amp;#39;&lt;/span&gt;]])

df_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(data_lst)
df_tags &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(tags_lst)

&lt;span style=&#34;color:#75715e&#34;&gt;# fit and transform the binarizer&lt;/span&gt;
mlb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MultiLabelBinarizer()
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mlb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(tags_lst)
Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3221&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;560&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Now we&amp;#39;ve transformed the target (tags) but we cannot directly perform
the algorithms on the text data, so we have to process and transform
them into vectors. In order to do this, we will use &lt;code class=&#34;verbatim&#34;&gt;TfidfVectorizer&lt;/code&gt; to
preprocess, tokenize, filter stop words and transform the text data. The
&lt;code class=&#34;verbatim&#34;&gt;TfidfVectorizer&lt;/code&gt; implements the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&#34;&gt;&lt;em&gt;tf-idf&lt;/em&gt;&lt;/a&gt; (Term
Frequency-Inverse Document Frequency) to reflect how important a word
is to to a document in a collection of documents.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.feature_extraction.text &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; TfidfVectorizer

&lt;span style=&#34;color:#75715e&#34;&gt;# Use the default parameters for now, use_idf=True in default&lt;/span&gt;
vectorizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TfidfVectorizer()
&lt;span style=&#34;color:#75715e&#34;&gt;# Use the short descriptions for now for faster processing&lt;/span&gt;
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(df_data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;description)
X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3221&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;35506&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
As mentioned in the beginning, this is a multi-label classification
problem, we will use &lt;code class=&#34;verbatim&#34;&gt;OneVsRestClassifier&lt;/code&gt; to tackle our problem. And
firstly we will use the SVM (Support Vector Machines) with linear
kernel, implemented as &lt;code class=&#34;verbatim&#34;&gt;LinearSVC&lt;/code&gt; in scikit-learn, to do the
classification.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.multiclass &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; OneVsRestClassifier
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.svm &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; LinearSVC
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; train_test_split

&lt;span style=&#34;color:#75715e&#34;&gt;# Use default parameters, and train and test with small set of samples.&lt;/span&gt;
clf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; OneVsRestClassifier(LinearSVC())

&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.utils &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; resample

X_sample, Y_sample &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; resample(
    X, Y, n_samples&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# X_sample_test, Y_sample_test = resample(&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#     X, Y, n_samples=10, replace=False, random_state=1)&lt;/span&gt;

X_sample_train, X_sample_test, Y_sample_train, Y_sample_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(
    X_sample, Y_sample, test_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;)

clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_sample, Y_sample)
Y_sample_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_sample_test)

&lt;span style=&#34;color:#75715e&#34;&gt;# Inverse transform the vectors back to tags&lt;/span&gt;
pred_transformed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mlb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inverse_transform(Y_sample_pred)
test_transformed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mlb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inverse_transform(Y_sample_test)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (t, p) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(test_transformed, pred_transformed):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tags: {t} predicted as: {p}&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;pre class=&#34;example&#34;&gt;
tags: (&#39;javascript&#39;,) predicted as: (&#39;javascript&#39;,)
tags: (&#39;erasure-code&#39;, &#39;storage&#39;) predicted as: ()
tags: (&#39;mysql&#39;, &#39;network&#39;) predicted as: ()
tags: (&#39;token&#39;,) predicted as: ()
tags: (&#39;flask&#39;, &#39;python&#39;, &#39;web&#39;) predicted as: ()
tags: (&#39;refactoring&#39;,) predicted as: ()
tags: (&#39;emacs&#39;,) predicted as: ()
tags: (&#39;async&#39;, &#39;javascript&#39;, &#39;promises&#39;) predicted as: (&#39;async&#39;, &#39;javascript&#39;)
tags: (&#39;neural-networks&#39;,) predicted as: ()
tags: (&#39;kubernetes&#39;,) predicted as: (&#39;kubernetes&#39;,)
&lt;/pre&gt;
&lt;p&gt;
Though not very satisfied, this classifier predicted right a few tags.
Next we&amp;#39;ll try to search for the best parameters for the classifier and
train with fulltext of articles.
&lt;/p&gt;
&lt;h2 id=&#34;search-for-best-model-parameters-for-svm-with-linear-kernel&#34;&gt;
Search for best model parameters for SVM with linear kernel
&lt;/h2&gt;
&lt;p&gt;
For the estimators &lt;code class=&#34;verbatim&#34;&gt;TfidfVectorizer&lt;/code&gt; and &lt;code class=&#34;verbatim&#34;&gt;LinearSVC&lt;/code&gt;, they both have
many parameters could be tuned for better performance. We&amp;#39;ll the
&lt;code class=&#34;verbatim&#34;&gt;GridSearchCV&lt;/code&gt; to search for the best parameters with the help of
&lt;code class=&#34;verbatim&#34;&gt;Pipeline&lt;/code&gt;.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.pipeline &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Pipeline
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; train_test_split, GridSearchCV


&lt;span style=&#34;color:#75715e&#34;&gt;# Split the dataset into training and test set, and use fulltext of articles:&lt;/span&gt;
X_train, X_test, Y_train, Y_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(
    df_data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fulltext, Y, test_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Build vectorizer classifier pipeline&lt;/span&gt;
clf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Pipeline([
    (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vect&amp;#39;&lt;/span&gt;, TfidfVectorizer()),
    (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;clf&amp;#39;&lt;/span&gt;, OneVsRestClassifier(LinearSVC())),
])

&lt;span style=&#34;color:#75715e&#34;&gt;# Grid search parameters, I minimized the parameter set based on previous&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# experience to accelerate the processing speed.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# And the combination of penalty=&amp;#39;l1&amp;#39; and loss=&amp;#39;squared_hinge&amp;#39; are not supported when dual=True&lt;/span&gt;
parameters &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vect__ngram_range&amp;#39;&lt;/span&gt;: [(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)],
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vect__max_df&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;],
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vect__min_df&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vect__use_idf&amp;#39;&lt;/span&gt;: [True, False],
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;clf__estimator__penalty&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;l1&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;l2&amp;#39;&lt;/span&gt;],
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;clf__estimator__C&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;],
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;clf__estimator__dual&amp;#39;&lt;/span&gt;: [False],
}

gs_clf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GridSearchCV(clf, parameters, cv&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, n_jobs&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
gs_clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_train, Y_train)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datetime
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; metrics


&lt;span style=&#34;color:#75715e&#34;&gt;# Predict the outcome on the testing set in a variable named y_predicted&lt;/span&gt;
Y_predicted &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gs_clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_test)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(metrics&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;classification_report(Y_test, Y_predicted))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(gs_clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;best_params_)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(gs_clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;best_score_)

&lt;span style=&#34;color:#75715e&#34;&gt;# Export some of the result cols&lt;/span&gt;
cols &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mean_test_score&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mean_fit_time&amp;#39;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;param_vect__ngram_range&amp;#39;&lt;/span&gt;,
]
df_result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(gs_clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cv_results_)
df_result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df_result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_values(by&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rank_test_score&amp;#39;&lt;/span&gt;)
df_result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df_result[cols]

timestamp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;now()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%Y-%m-&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;_%H-%M-%S&amp;#39;&lt;/span&gt;)
df_result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_html(
    f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;data/results/gridcv_results_{timestamp}_linearSVC.html&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Here we attach the top-5 performed classifiers with selected parameters.
&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;rank_test_score&lt;/th&gt;
      &lt;th&gt;mean_test_score&lt;/th&gt;
      &lt;th&gt;mean_fit_time&lt;/th&gt;
      &lt;th&gt;param_vect__max_df&lt;/th&gt;
      &lt;th&gt;param_vect__ngram_range&lt;/th&gt;
      &lt;th&gt;param_vect__use_idf&lt;/th&gt;
      &lt;th&gt;param_clf__estimator__penalty&lt;/th&gt;
      &lt;th&gt;param_clf__estimator__C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;64&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.140811&lt;/td&gt;
      &lt;td&gt;96.127405&lt;/td&gt;
      &lt;td&gt;0.8&lt;/td&gt;
      &lt;td&gt;(1, 4)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;l1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;70&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.140215&lt;/td&gt;
      &lt;td&gt;103.252332&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;(1, 4)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;l1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;58&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.140215&lt;/td&gt;
      &lt;td&gt;98.990952&lt;/td&gt;
      &lt;td&gt;0.9&lt;/td&gt;
      &lt;td&gt;(1, 4)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;l1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;154&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.140215&lt;/td&gt;
      &lt;td&gt;1690.433151&lt;/td&gt;
      &lt;td&gt;0.9&lt;/td&gt;
      &lt;td&gt;(1, 4)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;l1&lt;/td&gt;
      &lt;td&gt;1000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;68&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;0.139618&lt;/td&gt;
      &lt;td&gt;70.778621&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;(1, 3)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;l1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;headline-3&#34;&gt;
Training and testing with the best parameters
&lt;/h2&gt;
&lt;p&gt;
Based on the grid search results, we found the following parameters
combined with the default parameters have the best performance. Now
let&amp;#39;s see how it will perform.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;X_train, X_test, Y_train, Y_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(
    df_data, Y, test_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;)

clf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Pipeline([
    (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vect&amp;#39;&lt;/span&gt;, TfidfVectorizer(use_idf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
                             max_df&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;, ngram_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])),
    (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;clf&amp;#39;&lt;/span&gt;, OneVsRestClassifier(LinearSVC(penalty&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;l1&amp;#39;&lt;/span&gt;, C&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, dual&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False))),
])

clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fulltext, Y_train)


Y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fulltext)

&lt;span style=&#34;color:#75715e&#34;&gt;# Inverse transform the vectors back to tags&lt;/span&gt;
pred_transformed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mlb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inverse_transform(Y_pred)
test_transformed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mlb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inverse_transform(Y_test)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (title, t, p) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(X_test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title, test_transformed, pred_transformed):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Article title: {title} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
          f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Manual tags:  {t} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;
          f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;predicted as: {p}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Here below is a fraction of the list that shows the manually input tags and the predicted tags. We can see that usually the more frequently appeared and more popular tags have better change to be correctly predicted. Personally, I would say the prediction is satisfied to me comparing when I tag the articles manually. However, there&amp;#39;s much room for improvement.
&lt;/p&gt;
&lt;div class=&#34;src src-markdown&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;Article title: Will PWAs Replace Native Mobile Apps?
Manual tags:  (&amp;#39;pwa&amp;#39;,)
predicted as: (&amp;#39;pwa&amp;#39;,)

Article title: 基于Consul的分布式信号量实现
Manual tags:  (&amp;#39;consul&amp;#39;, &amp;#39;distributed-system&amp;#39;)
predicted as: (&amp;#39;microservices&amp;#39;, &amp;#39;multithreading&amp;#39;)

Article title: commit 和 branch 理解深入
Manual tags:  (&amp;#39;git&amp;#39;,)
predicted as: (&amp;#39;git&amp;#39;,)

Article title: Existential types in Scala
Manual tags:  (&amp;#39;scala&amp;#39;,)
predicted as: (&amp;#39;scala&amp;#39;,)

Article title: Calling back into Python from llvmlite-JITed code
Manual tags:  (&amp;#39;jit&amp;#39;, &amp;#39;python&amp;#39;)
predicted as: (&amp;#39;compiler&amp;#39;, &amp;#39;python&amp;#39;)

Article title: Writing a Simple Linux Kernel Module
Manual tags:  (&amp;#39;kernel&amp;#39;, &amp;#39;linux&amp;#39;)
predicted as: (&amp;#39;linux&amp;#39;,)

Article title: Semantic segmentation with OpenCV and deep learning
Manual tags:  (&amp;#39;deep-learning&amp;#39;, &amp;#39;opencv&amp;#39;)
predicted as: (&amp;#39;deep-learning&amp;#39;, &amp;#39;image-classification&amp;#39;, &amp;#39;opencv&amp;#39;)

Article title: Transducers: Efficient Data Processing Pipelines in JavaScript
Manual tags:  (&amp;#39;javascript&amp;#39;,)
predicted as: (&amp;#39;javascript&amp;#39;,)

Article title: C++之stl::string写时拷贝导致的问题
Manual tags:  (&amp;#39;cpp&amp;#39;,)
predicted as: (&amp;#39;functional-programming&amp;#39;,)

Article title: WebSocket 浅析
Manual tags:  (&amp;#39;websocket&amp;#39;,)
predicted as: (&amp;#39;websocket&amp;#39;,)

Article title: You shouldn’t name your variables after their types for the same reason you wouldn’t name your pets “dog” or “cat”
Manual tags:  (&amp;#39;golang&amp;#39;,)
predicted as: (&amp;#39;golang&amp;#39;,)

Article title: Introduction to Data Visualization using Python
Manual tags:  (&amp;#39;data-visualization&amp;#39;, &amp;#39;python&amp;#39;)
predicted as: (&amp;#39;data-visualization&amp;#39;, &amp;#39;matplotlib&amp;#39;, &amp;#39;python&amp;#39;)

Article title: How JavaScript works: A comparison with WebAssembly + why in certain cases it’s better to use it over JavaScript
Manual tags:  (&amp;#39;javascript&amp;#39;, &amp;#39;webassembly&amp;#39;)
predicted as: (&amp;#39;javascript&amp;#39;, &amp;#39;webassembly&amp;#39;)

Article title: Parsing logs 230x faster with Rust
Manual tags:  (&amp;#39;log&amp;#39;, &amp;#39;rust&amp;#39;)
predicted as: (&amp;#39;rust&amp;#39;,)

Article title: Troubleshooting Memory Issues in Java Applications
Manual tags:  (&amp;#39;java&amp;#39;, &amp;#39;memory&amp;#39;)
predicted as: (&amp;#39;java&amp;#39;,)

Article title: How to use Docker for Node.js development
Manual tags:  (&amp;#39;docker&amp;#39;, &amp;#39;node.js&amp;#39;)
predicted as: (&amp;#39;docker&amp;#39;,)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;headline-4&#34;&gt;
A glance at the different evaluation metrics
&lt;/h2&gt;
&lt;p&gt;
Now let&amp;#39;s have a look at the evaluation metrics on the prediction performance. Evaluating multi-label classification is very different from evaluating binary classification. There&amp;#39;re quite many different evaluation methods for different situations in &lt;a href=&#34;https://scikit-learn.org/stable/modules/model_evaluation.html&#34;&gt;the model evaluation part of scikit-learn&amp;#39;s documentation&lt;/a&gt;. We will take a look at the ones that suit this problem.
&lt;/p&gt;
&lt;p&gt;
We can start with the &lt;code class=&#34;verbatim&#34;&gt;accuracy_score&lt;/code&gt; function in &lt;code class=&#34;verbatim&#34;&gt;metrics&lt;/code&gt; module. As mentioned in scikit-learn documentation, in multi-label classification, a subset accuracy is 1.0 when the entire set of predicted labels for a sample matches strictly with the true label set. The equation is simple like this:
&lt;/p&gt;
&lt;div class=&#34;export-block&#34;&gt;
$$\operatorname{accuracy}(y, \hat{y})=\frac{1}{n_{\text {samples }}} \sum_{i=0}^{n_{\text {minples }}-1} 1\left(\hat{y}_{i}=y_{i}\right)$$&lt;/div&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; metrics
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt

metrics&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;accuracy_score(Y_test, Y_pred)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;src src-md&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;0.26356589147286824&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
The score is somehow low. But we should be noted that for this problem, an inexact match of the labels is acceptable in many cases, e.g., an article talks about the golang&amp;#39;s interface is predicted with an only label &lt;code class=&#34;verbatim&#34;&gt;golang&lt;/code&gt; while it was manually labeled with &lt;code class=&#34;verbatim&#34;&gt;golang&lt;/code&gt; and &lt;code class=&#34;verbatim&#34;&gt;interface&lt;/code&gt;. So to my opinion, this &lt;code class=&#34;verbatim&#34;&gt;accuracy_score&lt;/code&gt; is not a good evaluation metric for this problem.
&lt;/p&gt;
&lt;p&gt;
Now let&amp;#39;s see the &lt;code class=&#34;verbatim&#34;&gt;classification_report&lt;/code&gt; that presents averaged precision, recall and f1-score.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(metrics&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;classification_report(Y_test, Y_pred))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;precision&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;recall&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;f1-score&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;support&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;micro&lt;/td&gt;
&lt;td&gt;avg&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.74&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.42&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.54&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;1186&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;macro&lt;/td&gt;
&lt;td&gt;avg&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.17&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.13&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.14&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;1186&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;weighted&lt;/td&gt;
&lt;td&gt;avg&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.60&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.42&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;0.48&lt;/td&gt;
&lt;td class=&#34;align-right&#34;&gt;1186&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
Let&amp;#39;s look at the &lt;strong&gt;micro&lt;/strong&gt; row. Why? Let me quote scikit-learn&amp;#39;s documentation:
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
&amp;#34;micro&amp;#34; gives each sample-class pair an equal contribution to the overall metric (except as a result of sample-weight). Rather than summing the metric per class, this sums the dividends and divisors that make up the per-class metrics to calculate an overall quotient. Micro-averaging may be preferred in multilabel settings, including multiclass classification where a majority class is to be ignored.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
Here we&amp;#39;re more interested in the average precision, which is 0.74. As we mentioned, for this problem and for me, it&amp;#39;s more important to not predict a label that should be negative to an article. Some of the labels for an article, e.g., the label &lt;code class=&#34;verbatim&#34;&gt;interface&lt;/code&gt; for the just mentioned article, are less important. So I&amp;#39;m OK for having a low score of recall, which measure how good the model predicts all the labels as the manually labeled.
&lt;/p&gt;
&lt;p&gt;
However, there&amp;#39;s much room for improvement.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
Many of the labels have very few appearances or even once. These labels could be filtered out or oversampling with text augmentation to mitigate the impact to model performance.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
The training-test set split should be controlled by methods like stratified sampling, so that all the labels would appear in both sets with similar percentages. But again this problem is unlikely to be solved by now since there isn&amp;#39;t enough samples.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
Another problem to be though about is, the training samples are not equally labeled, i.e., for the same example all the articles talking about golang&amp;#39;s interface, some of them labeled with &lt;code class=&#34;verbatim&#34;&gt;golang&lt;/code&gt; + &lt;code class=&#34;verbatim&#34;&gt;interface&lt;/code&gt; while some of them labeled only &lt;code class=&#34;verbatim&#34;&gt;golang&lt;/code&gt;.
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
